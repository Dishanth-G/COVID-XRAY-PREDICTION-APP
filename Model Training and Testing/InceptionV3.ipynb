{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/train\"\n",
    "VAL_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/test\"\n",
    "\n",
    "\n",
    "TRAIN_COVID_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/train/COVID19\"\n",
    "TRAIN_NORMAL_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/train/NORMAL\"\n",
    "TRAIN_PNE_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/train/PNEUMONIA\"\n",
    "\n",
    "\n",
    "VAL_NORMAL_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/test/NORMAL\"\n",
    "VAL_PNEU_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/test/PNEUMONIA\"\n",
    "VAL_COVID_PATH = \"/kaggle/input/chest-xray-covid19-pneumonia/Data/test/COVID19\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=1/255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5144 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COVID19': 0, 'NORMAL': 1, 'PNEUMONIA': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1288 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_generator = generator.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying InceptionV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "stepsperepoch=9\n",
    "validationsteps=1\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=100)\n",
    "mc = ModelCheckpoint(\"own.h5\", monitor='val_loss',save_best_only=True, mode='min',verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=3,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 3)            6147        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,808,931\n",
      "Trainable params: 21,774,499\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.3464 - accuracy: 0.6632\n",
      "Epoch 00001: val_loss improved from inf to 0.99729, saving model to own.h5\n",
      "9/9 [==============================] - 16s 2s/step - loss: 1.3464 - accuracy: 0.6632 - val_loss: 0.9973 - val_accuracy: 0.7812\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8856 - accuracy: 0.6893\n",
      "Epoch 00002: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.8856 - accuracy: 0.6893 - val_loss: 1.1645 - val_accuracy: 0.0625\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.7361\n",
      "Epoch 00003: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.7227 - accuracy: 0.7361 - val_loss: 1.3423 - val_accuracy: 0.5625\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.7986\n",
      "Epoch 00004: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.5412 - accuracy: 0.7986 - val_loss: 1.2568 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8194\n",
      "Epoch 00005: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.4358 - accuracy: 0.8194 - val_loss: 2.3497 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8264\n",
      "Epoch 00006: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.4629 - accuracy: 0.8264 - val_loss: 1.8320 - val_accuracy: 0.6875\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8403\n",
      "Epoch 00007: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.4209 - accuracy: 0.8403 - val_loss: 1.5439 - val_accuracy: 0.7188\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8438\n",
      "Epoch 00008: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.4108 - accuracy: 0.8438 - val_loss: 1.8295 - val_accuracy: 0.6875\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4560 - accuracy: 0.8160\n",
      "Epoch 00009: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.4560 - accuracy: 0.8160 - val_loss: 2.4250 - val_accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8646\n",
      "Epoch 00010: val_loss did not improve from 0.99729\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3690 - accuracy: 0.8646 - val_loss: 1.2289 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8715\n",
      "Epoch 00011: val_loss improved from 0.99729 to 0.91367, saving model to own.h5\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.3590 - accuracy: 0.8715 - val_loss: 0.9137 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8854\n",
      "Epoch 00012: val_loss improved from 0.91367 to 0.83736, saving model to own.h5\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.3357 - accuracy: 0.8854 - val_loss: 0.8374 - val_accuracy: 0.8125\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8924\n",
      "Epoch 00013: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2696 - accuracy: 0.8924 - val_loss: 2.7507 - val_accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9271\n",
      "Epoch 00014: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2302 - accuracy: 0.9271 - val_loss: 2.1381 - val_accuracy: 0.6250\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.9167\n",
      "Epoch 00015: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3132 - accuracy: 0.9167 - val_loss: 1.9349 - val_accuracy: 0.5938\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.8715\n",
      "Epoch 00016: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3142 - accuracy: 0.8715 - val_loss: 2.7277 - val_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.9028\n",
      "Epoch 00017: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2472 - accuracy: 0.9028 - val_loss: 2.1016 - val_accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.8958\n",
      "Epoch 00018: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2586 - accuracy: 0.8958 - val_loss: 3.1064 - val_accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9028\n",
      "Epoch 00019: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2607 - accuracy: 0.9028 - val_loss: 1.8903 - val_accuracy: 0.4688\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9097\n",
      "Epoch 00020: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2520 - accuracy: 0.9097 - val_loss: 2.3146 - val_accuracy: 0.7188\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8924\n",
      "Epoch 00021: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3207 - accuracy: 0.8924 - val_loss: 3.2362 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.9167\n",
      "Epoch 00022: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2712 - accuracy: 0.9167 - val_loss: 2.7146 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9236\n",
      "Epoch 00023: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2044 - accuracy: 0.9236 - val_loss: 2.0554 - val_accuracy: 0.7188\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9306\n",
      "Epoch 00024: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2362 - accuracy: 0.9306 - val_loss: 2.7236 - val_accuracy: 0.7188\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9028\n",
      "Epoch 00025: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2658 - accuracy: 0.9028 - val_loss: 4.8530 - val_accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9340\n",
      "Epoch 00026: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1968 - accuracy: 0.9340 - val_loss: 3.0751 - val_accuracy: 0.6250\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9375\n",
      "Epoch 00027: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2015 - accuracy: 0.9375 - val_loss: 3.5726 - val_accuracy: 0.5938\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9286\n",
      "Epoch 00028: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1776 - accuracy: 0.9286 - val_loss: 2.5405 - val_accuracy: 0.6562\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9444\n",
      "Epoch 00029: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1628 - accuracy: 0.9444 - val_loss: 1.2102 - val_accuracy: 0.7812\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9429\n",
      "Epoch 00030: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1808 - accuracy: 0.9429 - val_loss: 2.0570 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9201\n",
      "Epoch 00031: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1908 - accuracy: 0.9201 - val_loss: 2.2168 - val_accuracy: 0.5938\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9549\n",
      "Epoch 00032: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1498 - accuracy: 0.9549 - val_loss: 3.7165 - val_accuracy: 0.3750\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9375\n",
      "Epoch 00033: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2014 - accuracy: 0.9375 - val_loss: 2.9701 - val_accuracy: 0.6562\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.9549\n",
      "Epoch 00034: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1227 - accuracy: 0.9549 - val_loss: 3.6364 - val_accuracy: 0.5938\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9062\n",
      "Epoch 00035: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2770 - accuracy: 0.9062 - val_loss: 2.5211 - val_accuracy: 0.5625\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9549\n",
      "Epoch 00036: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1827 - accuracy: 0.9549 - val_loss: 2.0554 - val_accuracy: 0.5938\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9306\n",
      "Epoch 00037: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1680 - accuracy: 0.9306 - val_loss: 1.7233 - val_accuracy: 0.5625\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9653\n",
      "Epoch 00038: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1298 - accuracy: 0.9653 - val_loss: 2.5585 - val_accuracy: 0.5625\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9444\n",
      "Epoch 00039: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1685 - accuracy: 0.9444 - val_loss: 1.6776 - val_accuracy: 0.6875\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9375\n",
      "Epoch 00040: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1708 - accuracy: 0.9375 - val_loss: 0.9485 - val_accuracy: 0.8438\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9618\n",
      "Epoch 00041: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1011 - accuracy: 0.9618 - val_loss: 1.8321 - val_accuracy: 0.7188\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9410\n",
      "Epoch 00042: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1220 - accuracy: 0.9410 - val_loss: 1.7679 - val_accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9444\n",
      "Epoch 00043: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1193 - accuracy: 0.9444 - val_loss: 1.6157 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9688\n",
      "Epoch 00044: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1028 - accuracy: 0.9688 - val_loss: 1.3782 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9479\n",
      "Epoch 00045: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1510 - accuracy: 0.9479 - val_loss: 1.4644 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9340\n",
      "Epoch 00046: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1844 - accuracy: 0.9340 - val_loss: 1.8289 - val_accuracy: 0.6562\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9688\n",
      "Epoch 00047: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1038 - accuracy: 0.9688 - val_loss: 1.6024 - val_accuracy: 0.6875\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.9062\n",
      "Epoch 00048: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2036 - accuracy: 0.9062 - val_loss: 0.9924 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9201\n",
      "Epoch 00049: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1935 - accuracy: 0.9201 - val_loss: 1.4317 - val_accuracy: 0.6562\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.9375\n",
      "Epoch 00050: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1574 - accuracy: 0.9375 - val_loss: 1.1609 - val_accuracy: 0.6875\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9097\n",
      "Epoch 00051: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2001 - accuracy: 0.9097 - val_loss: 1.0552 - val_accuracy: 0.7812\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9479\n",
      "Epoch 00052: val_loss did not improve from 0.83736\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1348 - accuracy: 0.9479 - val_loss: 1.1026 - val_accuracy: 0.6875\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9549\n",
      "Epoch 00053: val_loss improved from 0.83736 to 0.58892, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1833 - accuracy: 0.9549 - val_loss: 0.5889 - val_accuracy: 0.7812\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9410\n",
      "Epoch 00054: val_loss improved from 0.58892 to 0.40061, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1530 - accuracy: 0.9410 - val_loss: 0.4006 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9549\n",
      "Epoch 00055: val_loss did not improve from 0.40061\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1350 - accuracy: 0.9549 - val_loss: 0.6352 - val_accuracy: 0.7812\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9583\n",
      "Epoch 00056: val_loss improved from 0.40061 to 0.24945, saving model to own.h5\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1367 - accuracy: 0.9583 - val_loss: 0.2494 - val_accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9549\n",
      "Epoch 00057: val_loss did not improve from 0.24945\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1280 - accuracy: 0.9549 - val_loss: 1.0013 - val_accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9479\n",
      "Epoch 00058: val_loss did not improve from 0.24945\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1333 - accuracy: 0.9479 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9583\n",
      "Epoch 00059: val_loss did not improve from 0.24945\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1052 - accuracy: 0.9583 - val_loss: 0.8243 - val_accuracy: 0.7812\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9444\n",
      "Epoch 00060: val_loss did not improve from 0.24945\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1478 - accuracy: 0.9444 - val_loss: 0.7306 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9549\n",
      "Epoch 00061: val_loss did not improve from 0.24945\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1066 - accuracy: 0.9549 - val_loss: 0.5115 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9549\n",
      "Epoch 00062: val_loss improved from 0.24945 to 0.11250, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1221 - accuracy: 0.9549 - val_loss: 0.1125 - val_accuracy: 0.9688\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.9479\n",
      "Epoch 00063: val_loss improved from 0.11250 to 0.07285, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1507 - accuracy: 0.9479 - val_loss: 0.0729 - val_accuracy: 0.9688\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9514\n",
      "Epoch 00064: val_loss did not improve from 0.07285\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1039 - accuracy: 0.9514 - val_loss: 0.4798 - val_accuracy: 0.8438\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9375\n",
      "Epoch 00065: val_loss did not improve from 0.07285\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1435 - accuracy: 0.9375 - val_loss: 0.3449 - val_accuracy: 0.8438\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9479\n",
      "Epoch 00066: val_loss did not improve from 0.07285\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1473 - accuracy: 0.9479 - val_loss: 0.2764 - val_accuracy: 0.9062\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9549\n",
      "Epoch 00067: val_loss improved from 0.07285 to 0.06172, saving model to own.h5\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1384 - accuracy: 0.9549 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9410\n",
      "Epoch 00068: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1698 - accuracy: 0.9410 - val_loss: 0.2396 - val_accuracy: 0.9688\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9549\n",
      "Epoch 00069: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1491 - accuracy: 0.9549 - val_loss: 0.2556 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9514\n",
      "Epoch 00070: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1405 - accuracy: 0.9514 - val_loss: 0.3156 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9444\n",
      "Epoch 00071: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1871 - accuracy: 0.9444 - val_loss: 0.1461 - val_accuracy: 0.9062\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9653\n",
      "Epoch 00072: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1013 - accuracy: 0.9653 - val_loss: 0.3093 - val_accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9653\n",
      "Epoch 00073: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1112 - accuracy: 0.9653 - val_loss: 0.2318 - val_accuracy: 0.9375\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9653\n",
      "Epoch 00074: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1105 - accuracy: 0.9653 - val_loss: 0.2259 - val_accuracy: 0.9062\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9375\n",
      "Epoch 00075: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1984 - accuracy: 0.9375 - val_loss: 0.0880 - val_accuracy: 0.9688\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9583\n",
      "Epoch 00076: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1200 - accuracy: 0.9583 - val_loss: 0.3214 - val_accuracy: 0.8438\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9607\n",
      "Epoch 00077: val_loss did not improve from 0.06172\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1203 - accuracy: 0.9607 - val_loss: 0.3349 - val_accuracy: 0.9062\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9757\n",
      "Epoch 00078: val_loss improved from 0.06172 to 0.03404, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0642 - accuracy: 0.9757 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9653\n",
      "Epoch 00079: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0972 - accuracy: 0.9653 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9618\n",
      "Epoch 00080: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1511 - accuracy: 0.9618 - val_loss: 0.2086 - val_accuracy: 0.9062\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9514\n",
      "Epoch 00081: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1487 - accuracy: 0.9514 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9479\n",
      "Epoch 00082: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1499 - accuracy: 0.9479 - val_loss: 0.1062 - val_accuracy: 0.9688\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9688\n",
      "Epoch 00083: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1028 - accuracy: 0.9688 - val_loss: 0.1717 - val_accuracy: 0.9375\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9549\n",
      "Epoch 00084: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1247 - accuracy: 0.9549 - val_loss: 0.3440 - val_accuracy: 0.9062\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9479\n",
      "Epoch 00085: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1218 - accuracy: 0.9479 - val_loss: 0.2932 - val_accuracy: 0.9062\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9653\n",
      "Epoch 00086: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1278 - accuracy: 0.9653 - val_loss: 0.2788 - val_accuracy: 0.8750\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9653\n",
      "Epoch 00087: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1211 - accuracy: 0.9653 - val_loss: 0.1072 - val_accuracy: 0.9375\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9410\n",
      "Epoch 00088: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1309 - accuracy: 0.9410 - val_loss: 0.2147 - val_accuracy: 0.8750\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9340\n",
      "Epoch 00089: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1714 - accuracy: 0.9340 - val_loss: 0.1015 - val_accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9618\n",
      "Epoch 00090: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1344 - accuracy: 0.9618 - val_loss: 0.2196 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9757\n",
      "Epoch 00091: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0840 - accuracy: 0.9757 - val_loss: 0.1546 - val_accuracy: 0.9062\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9688\n",
      "Epoch 00092: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0944 - accuracy: 0.9688 - val_loss: 0.0573 - val_accuracy: 0.9688\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9688\n",
      "Epoch 00093: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1046 - accuracy: 0.9688 - val_loss: 0.0952 - val_accuracy: 0.9688\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9618\n",
      "Epoch 00094: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1025 - accuracy: 0.9618 - val_loss: 0.1176 - val_accuracy: 0.9688\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9826\n",
      "Epoch 00095: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0667 - accuracy: 0.9826 - val_loss: 0.0676 - val_accuracy: 0.9688\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9464\n",
      "Epoch 00096: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1105 - accuracy: 0.9464 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9792\n",
      "Epoch 00097: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0921 - accuracy: 0.9792 - val_loss: 0.1331 - val_accuracy: 0.9375\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9688\n",
      "Epoch 00098: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1283 - accuracy: 0.9688 - val_loss: 0.1538 - val_accuracy: 0.9375\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9722\n",
      "Epoch 00099: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.1600 - val_accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9583\n",
      "Epoch 00100: val_loss did not improve from 0.03404\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1119 - accuracy: 0.9583 - val_loss: 0.1614 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[annealer,mc,es],\n",
    "    steps_per_epoch=stepsperepoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = validationsteps\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 37s 906ms/step - loss: 0.1411 - accuracy: 0.9503\n",
      "Validation Loss = 0.14113329350948334\n",
      "Validation Accuracy = 0.9503105878829956\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(validation_generator)\n",
    "print (\"Validation Loss = \" + str(preds[0]))\n",
    "print (\"Validation Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy : 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hUVf6435PeE0ggEAKEktB76KgIIirWtWKvqOuuZV3Xddf9qd+tbnF1XXvHXta2dsW10Am9J7QUIJBCes+c3x9n7sydyZ2SMkkg532ePDO3zrmT5HzOpwspJRqNRqPpuQR19QA0Go1G07VoQaDRaDQ9HC0INBqNpoejBYFGo9H0cLQg0Gg0mh6OFgQajUbTw9GCQNMjEEKkCSGkECLEj3OvFUIs74xxaTTdAS0INN0OIcQBIUSDECLJbf8m+2Se1jUjcxlLtBCiSgjxWVePRaNpL1oQaLor+4HFxoYQYhwQ2XXDacFFQD1wuhCif2d+sD9ajUbTGrQg0HRXXgWuNm1fAyw1nyCEiBdCLBVCFAkhcoUQ9wshguzHgoUQfxdCFAsh9gGLLK59QQhxWAhxUAjxByFEcCvGdw3wNLAFuMLt3nOEECuFEGVCiHwhxLX2/ZFCiH/Yx1ouhFhu3zdXCFHgdo8DQojT7O8fFEK8J4R4TQhRAVwrhJgmhFhl/4zDQoh/CyHCTNePEUJ8LYQoFUIcEUL8RgjRTwhRI4RINJ03xf79hbbi2TUnGFoQaLorq4E4IcQo+wR9KfCa2zmPA/HAUOAUlOC4zn7sJuBsYBKQiVrBm3kFaAKG2885HbjRn4EJIQYBc4HX7T9Xux373D62PsBEYJP98N+BKcAsoDfwK8Dmz2cC5wHvAQn2z2wG7gKSgJnAfOCn9jHEAt8AXwAp9mdcJqUsBL4DLjHd90rgLSllo5/j0JyISCn1j/7pVj/AAeA04H7gz8AZwNdACCCBNCAYZZoZbbruZuA7+/tvgVtMx063XxsCJNuvjTQdXwz8z/7+WmC5l/HdD2yyv09BTcqT7Nv3AR9YXBME1AITLI7NBQqsvgP7+weBH3x8Z3can2t/lo0ezrsUWGF/HwwUAtO6+neuf7r2R9saNd2ZV4EfgCG4mYVQK+EwINe0LxcYYH+fAuS7HTMYDIQCh4UQxr4gt/O9cTXwHICU8pAQ4nuUqWgjMBDYa3FNEhDh4Zg/uIxNCJEBPILSdqJQAm69/bCnMQB8BDwthBgKZADlUsq1bRyT5gRBm4Y03RYpZS7KaXwW8L7b4WKgETWpGwwCDtrfH0ZNiOZjBvkojSBJSplg/4mTUo7xNSYhxCwgHbhPCFEohCgEpgOL7U7cfGCYxaXFQJ2HY9Woydz4jGCUWcmMe5ngp4BdQLqUMg74DWBINU9jQEpZB7yD8mtchRK2mh6OFgSa7s4NwDwpZbV5p5SyGTWh/VEIESuEGAz8Aqcf4R3gdiFEqhCiF/Br07WHga+Afwgh4oQQQUKIYUKIU/wYzzUoM9VolP1/IjAWNZGfibLfnyaEuEQIESKESBRCTJRS2oAXgUeEECl2Z/ZMIUQ4kA1ECCEW2Z229wPhPsYRC1QAVUKIkcCtpmOfAP2EEHcKIcLt38900/GlKPPXubT0u2h6IFoQaLo1Usq9UsosD4d/jlpN7wOWA2+gJltQppsvgc3ABlpqFFejTEs7gGMoR6zXMFAhRATK0fq4lLLQ9LMftbK+RkqZh9Jg7gZKUY7iCfZb/BLYCqyzH3sYCJJSlqMcvc+jNJpqwCWKyIJfApcDlfZnfds4IKWsBBYA56B8ADnAqabjK1BO6g1SygM+PkfTAxBS6sY0Gk1PQwjxLfCGlPL5rh6LpuvRgkCj6WEIIaaizFsD7dqDpoejTUMaTQ9CCPEKKsfgTi0ENAZaI9BoNJoejtYINBqNpodz3CWUJSUlybS0tK4ehkaj0RxXrF+/vlhK6Z6fAhyHgiAtLY2sLE/RhBqNRqOxQgiR6+mYNg1pNBpND0cLAo1Go+nhaEGg0Wg0PRwtCDQajaaHowWBRqPR9HACJgiEEC8KIY4KIbZ5OC6EEP8SQuwRQmwRQkwO1Fg0Go1G45lAagQvozpLeeJMVF33dGAJqr66RqPRaDqZgAkCKeUPqFK7njgPWCoVq4EEIYTXMsAajaYTqC6GTW9CV5efOboLvv2j82frey3PqT0GG18Dm7+tn7sJjbWQ9SI0d49W0V2ZUDYA1/Z7BfZ9h91PFEIsQWkNDBo0yP2wRqPpSDYshWUPQUxfGD6/68bxw19h239QjdckiCAYeTaERjjP2fIOfP4riEiAUWd31Uhbz5qn4ZsHIbpvtxh3VzqLhcU+yyWIlPJZKWWmlDKzTx/LDGmNRtNRFGer1+X/7PpxpJ8OD5bBhS+AtEHpPtdzinar1+X/7HoNxl8a62DVk+p93qquHYudrhQEBbj2lE0FDnXRWDQajUFxtlp9H/gRCtZ3zRhsNijeA4npajsp3Tk2M8ZYD2ZB7orOHWNb2fwmVB+FyN6Qv6arRwN0rSD4GLjaHj00Ayi395LVaDRdhZRQnAPjL4WIeFjRRVpBRQE01ToFQOJw9Vqc43pecQ6MuQCi+3S9BuODjXnHuOnlNTQvfwxSJsHkq+HQJmioob6puUvHFsjw0TeBVcAIIUSBEOIGIcQtQohb7Kd8huo1uwfVc/WngRqLRqPxk6ojUF+hJqqpN8HOT1pOvp2BfeW/u7mf2g6LhviBrhpBXTlUFUK/cTD9FtjzDRRu7bQh5pfWsHpfCf70dKmsa+Rnb2wkNPsTgsv2w5y7YNBMsDWyb8uPjHvwK+55dzPV9U2dMPKWBMxZLKVc7OO4BG4L1OdrNJo2YEz6Sekw5iew6t+w8l9w7uOdOoyS3O0kApd/cIwzD2/lt2eNJjIpHUpMQql4j32sGTB4ltIIVjwGFwa+DfPWgnKufnENx2oaGTsgjtvmDmfhmH4EBVm5PuHBj3dwuLyGFyI/JV+mMCBjEUENFQDsWP0lsID3NhSw7kApj142ibiIENYdKGXn4UrOnzSAiQMTAvo8x10Zak3PptkmqW1sJia8fX+6h8tr+enrG7jztAxOybAOQJBSctPS9cwb2ZfLpx9n0Wqf3g3bP3Buj7sEzvyL7+uMFXdSBsT0gYlXqCii+Q9CdKJfH11UWU9RZb3lsaF9ookIDYZP7oLeQ2HWz1uck19aw7oVK5hPNGdMG8trq/NYva+UN1MHk5S/FiElCOE61shekHkdrHoC5t3P9tpe3PPuFn65MIN5I5M9P25VPUcr1FiDgiCjb6zHydwg60Ap1720jrjIUG6fn87SVbl8+9YjTAt5C+NSISAiJJjw0CAam2z8pr6JP0QLIpsquLfxJs49UMbs4Uk0Jo4g5uh6rp5xIwtGJ3PX25s4/wmnryNIwNvr8nn+mkxmD0/yOq72oAWB5rjiwY+38+nWw3x6+xz6x0danlNd38SPOcWcPjrZ4z/1Hz7Zyca8Mn7x9ia+uPNk+sSGtzhn1d4Svtl5hLKahuNPEOz4CGL6weCZsP8HyP7CT0GQA6HREJuitkefB1kvQOEWGHaqz8u3HSznJ0+tpKHJOq7/nAkpPH7RSNjwKgyc5iIImm2S7COVLHk1i3/YCghNHskffzKeM8el8It3NvHYZvhDaBX3Lf2SiaNHc3F5DkFBIdArTd1gxm2w+mmalj/OHTnnsudoFTe/up7HLpvEWeNapihtyDvG4mdXU28a608mDeCRSyd6fL6Ve4u54eUs+sdH8NqN00lJiOTqmWkce+pPhJSFsyv+JABKquoprmogsjmYZpuNuMhQFo7tR1NYPMtWZVK5JpfZw5PYFjSKyeIrhs8cSGpiLJ/fcTJLVx0gMSacaUN6ERcRylUvrOW6l9fx5OWTOW20Z6HWHrQg0Bw3HKtu4J2sfOqbbPzy3c28ev10y4n+95/s4K11+fz2rFHcdPLQFseX5xTz6dbD/GTyAD7Zcphf/2cLz1+TiRCu91q6SvXx2FJQTl1js1rJBoDq+iY25pWx9kAp2YWVZCTHMHVIbyYN6tVC8zlaUccjX2ezcGw/Th3R1/qGtcegughm3Q6zb4evH4DVT6pInCAfbsHibEga7jwvKcO+P8enIKhtaOaOtzbSKyqUB88Z0+L7/N+uo7ydlc9d6UUMtTVCuUojemXlAd5cm8e+4moammzEhocwKbqI0P4LAJiTnsRXd51M1nelsPYlqgt2ce/OZtISVjM5fgihwaHqA+L6w4TLkBuWcqx2Ck9ecSovLt/Pz97YwF8vmsBFU1IdYyk4VsOSpVkkx0Vw35kjEULwQ04Rb6zJ46LMVGYNa7n6rmts5u53NjOgVyRv3jTDsXgIlk0klW2FyVcz/cyHAaVNrtpXwlPf7WVLQTnv3zCL4D4xAJzfsIOXVx7gQHE17xSl8mdRQ1xjLjCW+KhQfj4/3eVz31oyg2teWsstr63n0csmcvb4FO+/wzagBYEm4FTXN3Hx06s4f1IKS04e5thfUdfIjS9nMX9UX24+ZZjLNfd/uJWiynqevnKKY0IxhMD1s4fw4or9vLTyADfMGeJy3ca8Y7y1Lp+4iBD+9uVu5qQnMap/nON4Q5ONBz7exuDEKP50wTjGpMTz+0928ObafJdV/6GyWr7aUcjIfrHsKqxk28FyMtN6t+n51+ce46nv9rDzcCXPXj2FMSnxjmNvrc3j/320nYZmG0ECBvaO4qsdhdi+hZAgwbkTUrh17jDSk2P5escRfvXeZo7VNPLe+gKXSWFrQTl3v7uJPUermChyeD8MHlrdyJTYQ5wVl0pQcwOy+ij5DXFEhQeTFNNSAwJoOLKbjYzgzj8v46krpzAxtR+ExUJJDh9uPMifPtvJwN5RTE3rzfShvZkzPInQYCU0/vL5TvYWVfPaDdOZk95yIp05LJEvtheyfvnnDAWoOMTK7CM88PF2JgxM4NpZaQzvG8OsAaGEPnPUGTEEJESFcdqck2AtPHZaFKeETCDx41x+rOtH+cYCzhzbn4jQYNYNuIopG17jkbQ1nDLucuaO6MOSpev55bubWbGnmFvnDiMlIZIbX8mivsnGW0syGd43FoC5I/rwY04RD3y0nc/uOMnxXAavrc7lcHmdixAAlLbUWAODZjh2CSGYNSyJWcOSkFK6CMXF0wfx/PL93PDKOurrh0M4kL8a+o21/J30ig7j9Runc8MrWdQ2BCa6SAsCTcD5cNNBdhyuYMfhCgYkRLFofH+amm3c9voG1h4o5WBZLUtOHur4Z6lrbOY/6w9S29jMp1sPc/b4FJptkldX5zJ9SG9+d/Yo8kprePiLXcwZnsSIfuofudkm+X8fbSc5Lpz3bpnFBU+u5K63N/HhbbMdq/kXV+xnb1E1L16bSURoMNfNSuN/u47y+092MG1Ib4b3Vau2N9bkIYG/XjSec/+9gnUHjrVaEOwrquI3H2xl9b5SekWFEhocxOJnV/Py9dOYPKgXLyzfz+8/2cFJ6UncMGcIUwb3IjYilKr6JjbkHuPbXUd5e10+7288yISBCWzOL2N0/zheum4af/x0B7e/uZHq+iaO1TTyj692kxQTzq1zhzGuaBfsgRxbCi+9sZHFCWX8Gbju0Q/4rnoQUWHBvHDNVGYOc9r8tx8q55FPN/FCVQHrmAXhcMVzq3nh2qnMSErn8N4t3PXjJsamxGOTkud/3MfT3+8ltVckN58yjOTYcF5Zlcv1s4dYCgGA+MhQbp07jMRvNkAwYGviL+99z9A+fXnrphlEhtk1LiN3wdBGDGKVUBIle7hwYT/kp0fYHD6Tu9/ezK/e28K4AfHkldbwaOh0Ti77AOr/QFR4LM9fk8k/v87m1dW5fLDxIAMSIimsqOOla6c6hABARGgwD5w9hhuXZvHyigMu2mRVfRNPfreXk9KTXL43APJWq9eBM7DCXTMa1ieGGUN7s3pfKZmDMqC2v7rH1But/5CA2IhQ3rxpBsE+/BdtRZeh1rSL3YWVXP3iWm58JYvffbiN53/cR02DMwROSsnSlbmM7BdL5uBe3P3uJrYUlPH7T3bwY04xJ6UncbCslt1HKh3XrNpXQm1jM/GRofz+kx1U1Tfx3e6jFByr5eqZaQgh+MuF44iLCOHW19bzfXYRUkreXJvH1oPl/HbRaAb2juJvF41nV2Elf/psJ59tPcyDH2/nsW9yWDA62eFADAoS/P3iCUSGBbP4udVkH6mkvqmZN9fmMX9kX8anJjC0TzRZB7yVzbLmj5/uZPuhCu5fNIrl987j/Z/Oold0GFc+v4Z739vC7z/ZwRlj+vH8NZnMHdGX2Ahl4ogJD+HkjD48eO4YVvx6HrfPT6espoElJw/lg9tmMXFgAq9cP43Zw5O49z9b+cvnu1gwOpnP7ziJexaO5IzkCggK5ZW7LuLJKyZTE6Ge9eTkOv7vvDEMSIjk2pfW8r/dR7HZJM/9sI/zn1hB9WHlfL3h/IV8eNts+idEcs2La9lY0wdZnM2pI/ry7i0z+eCns9n64EKevWoKfWLD+d2H21jy6noykmP41RkjvH4n18wYRGZwDsVBSliEVR/m0UsnOoUAOCOD3AWBEEpLKM6GslyErZHzFszlxWszuWGOWkgECUH/Rfch6sph/SuAmuDvO2sUK+6dxx3z02m2Sf7vvDGcbBEkcNroZOaN7Muj32RTWF7n2P/Cj/sprW7gl6dbPF/eKkgYrExTfnLVjDQAbjx5GAyc7hQmXgiUEACtEWj8QErJ/uJqiqsamJrWy7HCyS+t4eoX19DQZCM5LoJ1B0opr21kb1E1f/7JOADW7i9l95FKHr5wHPNHJXP+EytY/OxqqhuauXHOEJacPJRpf1rGsp1HGdlPmXCW7TxCVFgwz1w1hcueXc3jy3LYWVhJclw4p49Rk1pSTDj/WjyJu9/ZzDUvrmXsgDjyS2uZOTSRc8arf8hTR/blyhmDWLoql6WrcokMDWbqkN48dO4Yl+frFx/BW0tmcOXza7j0mVVckjmQkuoGrp6ZBsDUwb35ckchNpu09EkUV9VT19hMaq8ox76jFXV8l13EkpOHcuNJamUZHR7CuzfP5Irn1/B2Vj4/mTSAv140npBgz+ux3tFh/GJBBr9Y4DopRoWF8Pw1mfzti92M7B/HhZMHOFeexTmQOIzgkFDOGtefs4afAw//nOvHhsLMNM4en8JVL6xhydIsxg6IZ2NeGQtGJ/PPMZXwX4jsN5LIuAjeXjKDq15YyzdH47kntJSnL84gzK5ZRYYFc/qYfiwYnczqfaW8t76AW04Z2tKPUrgNEgZBhPrdRpblEEk1zzTM5eaQT7lxfCjjU91CI4uzwewENpOUAQeWOyKGQvqMYN7A5JaRQZtPUhFE05ZASBigTCx3LcjgLrfv0kFRNsT05YFzRrPgnz9w2bOruO3U4cxLrubAj29z3+AYJlQ0Qsk4SLSbMqWEvDUwbJ7H36EVZ43rx6e3z1FmwqqZsONDVTwvLMb7hUnpkDzG+zltQAsCjUcOFFfz1y93sXZ/KcVVDQBMG9KbP5w/lt7RYVz1whpqG5p595ZZDvPMnz7bybM/7OO8iSnMGJrI0tW5xEeGcu6EAUTaTRIXPbWS00b15b6zRhEcJBifGs+ynUe47dThSCn5dudR5gxPYsbQRC7JTOWF5ftpsknuOi3DxW47a1gS399zKh9uPMhT3++ltrGZh85zdVLev2g041MTSO8bw9gB8S3svgYZybG8Y5+kn/lhH0OTopljD9fLTOvF21n57C2qIj051uW6oxV1nPfEChqbJT/8ai5RYepf6v2NB2m2SS42OSgB+sZF8M7NM1m5t4Qzx3qOO/eH8JBg7j97dMsDxdnQd6RzOyJBTTAVBwElXN64aQbXv7yO7YfK+dMF41g8bSDi+28A4ZjkEmPCeXPJDHK+2wtr3iGsfB9ET3L5KCEEM4cltjSXAJQXwLNzYeyF8JNn1D57bZ2NcfOh5lMWDLCovlmcDb2GgOEENpOUDlveUhm5oBzbVsy5E167ELa+A5OutD7HTHMjPD8fxl3M4LMf4bmrM/nL57u4570tfB5+H/8UuXAEeBeIS4U7Nqnxle5T5SIGWZuFPCGEcPqKhp6iXj/yI61q9p2w4KFWfZY/aEHQjahtaHZVkTuBnYcrePr7vQQHCf5x8QSXSfSBj7eTdaCUhWP6MXVIb5qabfz9q2zOeuxHkuMiKKmu5/UbpzuEAMBdp2XwxbZC7nt/Ky9fN5UvtxVy3ew0x3ON6BfLivvmERMW4pgE549M5tFl2RRX1XOkoo5D5XXceZpatd17xki+2FZIbWMzi6ebS1MpwkKCuGTqQC6ckkp5bSO9o8NcjkeEBnNJZsvrrEhLiubdW2byi3c2cdWMNMf4DN/AugPHXARBXWMzNy3NorS6gfomGy+tOOAQZu9k5TM1rRdD+7Rc4fWKDmPR+ABVXG9uhGP7YfS5zn1CQHyqI0oHlL3+7SUzqKpvIiHK/p0VZ6vVe2iky3mZU6bDGlQCV4qrIPDKqifA1ghb34V5v1X3zlsNMck88vOrkY88QLBdOLlQnNPSLGRgOJB3f6bKSkT2sj5v2HyVcbziMZhwue9oqcItKqP6wHIATsnow8npSSzfuodR7+eytt9lTLvgDji0QU3YW9+DiYudJp1WCgIX+o6CO7dCfZXvc6P8y+VoLdpH0E34ePMhxjzwBY98tZum5sDXVl+fe4wbXl7HmY/9yKdbDvP+hoN8u+uo4/iOQxV8n13ET08dziOXTmTxtEFcNTONb+8+hQsmDeBYTQNPXTGFKYNdHaiRYcH86YJx7C+uZvGzq2mWkitnDHY5Jy4i1GUlPH9UX6RU4YXLdh5FCGXWAbUq/dfiSfzh/LH0jY3AE8FBooUQaAspCZG8tWSmy0SdlhhFUkyYi5/AZpPc/c5mthws59+XT+a0UX155vu9lNc0siHvGPuKqrnYTwHUoRw7ALamlhNpfKpaoZsICQ5yCgGwh45aTMC9h6rCbu4F37xRUwrrX1YmExEEK/+t9uethkEziAoPRcQPbDEmmpugZK9LxJALxvgKt3gWFqCE3+w71Zh3f+Z7vMaEXrwbqkvstxCcFKGqnU474ypIHq0S7PqOgRWPqnDcvFVK40ry7hvxScIgdX9fP7GBySPQgqAbIKXk2R/2Eh4SzL++3cPFz6wit6Q6IJ/zY04Rlz27igufWsn6vGPcdVoGq38zn7TEKP725W5sNlU35env9xIdFsyV010n8cSYcP528QS2PbjQMVm7Myc9iYunpHKovI5TR/RlcGK013GNSYmjf3wEy3YeZdnOI0xITXAJz5s7oi+XTu26hC4hBJmDe5OVewxQ3+PfvtrNp1sP8+szRrJgdDJ3nz6CiromnvlhL++sKyAqLJhFFklMAceYrBPdJlILQeCCUe3TanINCVf2+tYIgrXPqZDKhX+C8Zeo7OTDW6A8T9XYcYwp3/W6slylRXia5A2hBJ6FhcHo85UT158S1XmrQNi1cXNF0LxVyl+RYu+kK4QyOxXtgpwv1bmDZvjWOLo5x/foTxA25pex7WAFv1k0iscXT2LP0SoW/Ws5BcdqOuwzpJTc/tYmrnphLfuKqrl/kT2K4rR0kmLCuWtBBrsKK/nvlkPkldTwyZZDXDFjMPFRFnZa8Gnb/u2iUZyc0YefzfNgwzUhhGDeyL58l32UzQXlzPcgYLqSzLRe5JXWcKSijr98vounvtvL4mmDWGIPMRzVP45zJ6Tw0ooDfLLlEIvG9Se6nWUw2oSj7ILb9x6XqpLMGmutr6s46Frt053EdP+LzzVUq8YrGWcos8fsO9S9P7xVHR84Xb3Gpzr8Fs7xe4gYMjCEkrdzDIJDVOayrxLVhsN31DkQHKZi+g3y1kD/iRDmDARgzE8gfhAs+736vo3nOY7RgqAbsHTlAWLDQ/jJpAGcMyGFD346m6r6Jv67ufVVueubmvlw40H2FrnaG7/ecYT/bj7EzacM5cd7T+XGk4a6TFTnjE9hZL9Y/vl1Nk/ZfQbXzx7ifnu/SYgKY6k9Xt4f5o/qS12jzf4+MOpvezD8BDe+ksUzP+zj6pmD+eP5Y118Kr9YkEFDs43qhmYumdoFZiFQE2lMP1VC2ky83Wld4aHlh7lujxVJ6VCyB2x+JDRtfA1qS1WFTYA+I2DEIjiyTZWv6Dde7Y8bADUl0GBa8HgSZC5jyfA+VjOTroSoJO8lqg2H79C5ygdimIma6uHg+pb2f0PAHN2utg0N5zhGO4u7mKLKej7bWsjl0wc5JubhfWOYkBrPF9sOc+vcYT7uoKiub+LNtXk89+M+jlTUkxwXzke3zaFffAS1Dc089N8dZCTH8MvTR1hGzgQFCe5ZOIIbXsniQEkel2YOpF+8Z5t8RzNrWBIRoUH0jgpjVP9Y3xd0MmNS4ogIDWLrwXJuPmUovz5jZItEobSkaK6blca63GNkDvZPAHY4xdnWq3pDEJTnO0MfXa4zVR21IikDmuvV9b3SlA/go59BQ2XLcw9vUclV5gl0zp2w+1NIzVQTKaiy0qC0AnPjGW9OYGOM2V/4Ng2BcnzPuAW+/QO8fLYy7YhgOO1BSLHXFDI7fEv3KW2msQ4Ob1bPbOUInnQlfP8XqK9snQO9m6IFQRfz9ro8GpptLRyqZ4ztz8Nf7OJgWS0DElQUR8GxGi58aiWZg3tz69xhjB0QT1lNA6+szOWllfspq2lk5tBE7l4wgof+u52blmbxzs0zeeq7PRwsq+WtJTM8hk8CzBvZl8mDEtiYX8aSU1rW6AkkEaHB3L1gBAlRoS0m2O5AaHAQdy8YQVhIEFfPHOxxjJbhnJ2FlGoiHXtRy2MOQeDBT3Boo+qfG+2hFay55lCvNFj9lHLCDpyuJlczyWNh/u9c9w2cpkxE5uxbs3AyJvVDm9T13hh7kTI/xfvpN5p6ExRkqf4FAIUbVU/mq+zVWc0O30EzVdntQxuhYK197BaCICwKzvyrEhyhnbdgChRaEHQhTc02Xl+Tx5zhSY7SBgZnjO3Hw1/s4otthY56Os/9sI+SqgZ+yC7i062HmZrWix2HKqhuaOa0UX25de5wpthXor2jw4sdppwAACAASURBVLjp1SyWvJrFmv2ljrh+bwgh+OelE9l5uJJhFmGPgcaqQFx3oruPj+piNdlZrZTjUgDhWRDkrVIrX09C2CEIstVkufZZGLkILnvd//Et+D/XbXfhVFeuzEdz7/N+n5SJztW8P0QmwOVvO7d/fEQJgsObof8EV4evYe/PWwUF61RntBgPwnGchcA9TtE+gi6itLqBP362k8PldVw9c3CL40OSohnZL5YvtxUCqqzt21n5XDBpACvum8c9C0dQVFnP/FHJfHHnSTx/zVSHEACVKv/bs0bxY04xYcFB/OasUX6Na3BiNGeM7dcxD6npXBz2dQtBEBIOMcnWgqDikIrW8RYLH52oeuwWZ8OGV6CuTIVntgd34ZS/DpDti8n3h8zrVSG95Y8q4Wl2+EYnKqGXu1KZjDzUDzrR0BpBJ1Na3cAT/9vDG2vyqG1s5ryJKR6do2eM7cdjy3I4WlnHa6tyqW+ycfMpQ4mLCOW2U4dz26neI3JumDMEm5QMSYohOe74V181PvDl8PUUQupvUlRSOhzZATlfw+A5MHBq28cKKjM3tj+U2yOHjBDO1Mz23dcXkQkw9XpY+TgMmKL2mR2+g2bApjdUPkaghVI3QWsEncihslouemolL688wJnj+vH1XSfz2GWTPBaTOnNsf6SEDzce5JVVuSwYlexSLdEXQgiWnDyMBQFqZqHpZhTnQEikChW1In6AtSDIXwOhUc5oHk8kpSu7ecVBZ0RQezHnEuSthv7jVX/iQDPjpyo/YNn/qZBRs8N30EwlBIz3PQAtCDqJ3JJqLn56FUWV9by9ZAaPXDKxRd0adzKSYxiSFM3fv8qmvLaRW/yMINJ0c6RU0SZW1FW0/b7uTWXcMTJ53ZOr8laplbFVbR8zhqaRPA6Gz2/7OF3GZBdOTQ32UM1Omnhj+8GExSoqKGWyq8PX0AKikqwjrE5AtCDoBDbnl3Hx06uobmjijZtm+F3XXgjBGWP70dBkY/qQ3n7H5Gu6Obs+gb9nKPu0mcJt8HCasx5/aynZo5ybnohPVYldNaaS2vWVULjVvwm4r73q5ew7PDuVW4thrjq8WY2tM00xs+9QWcqDZ7nu7zVEtepMm91xz9nN0T6CALLuQClP/G8P3+0uok9sOG8vmelSoM0fzp84gBeX7+eO+X7ETGuOD/LXqvILR7Y7K0+CWhHLZti7DFKntO6eNpuaUEef5/kcc7im0Yi+YB1Im38T8LB5cO1nLSfO9hA/UK3Kd/1XbXemczZxGNz0LfR2W/ULAdd8DOFx1tedgGhBECAe+Tqbfy3LoXd0GPcsHMGVMwYTH+lD9bZgRL9Ytj+00GvNes1xhpG8VZztKggMZ68fTUpaUH1U1eiJ9+AfANdwTUcy1Rq1Kk71w/EbFKRWyR2JMaat/7GvxDvZn+UpGcyfZLUTCC0IAoDNprplnZzRh2eunNLu0tJaCJxgGBO+e+0eYzt/rSrlENSKvxvDCRzvpbSFcczsMM5bpRqdRHTR6tdR+qJAlYvWdAl6hgkAWw+WU1RZzwWTUjq9v4Cmm9PUoEpFg7Mlo0Fxtor6aahUZqPWYETeeNMIohIhJMJ5bnOjyrjtysgYs+DqIaGa3REtCALAsp1HCBIwN6P7VdHUdDHH9is/QEikq0bQVK+SusZcoLbNpZD9waEReBEEQqhCb8a5hVuhsbprq2dG9lLfBWhB0IVoQdBG6hqbWbOvhCe/28OqvSUux77ZeZTMwb3pZTRKKdymOhppAkflEdUIpbtjmIWGz1cr8wZ734nSfcppO2yemqztLR39prxAZcu6Vx11Jz5VmZ4+/7WKoYeu1QiM7mmRvf2rJqoJCNpH0Eqq65u4573NfLPjKA32TmJJMeGOfrWHymrZcbiCX59p6hm74lElCFIm9Zi45E5n8xvwzYOQfrq9dEE3xRAEI85SYaQle1S9G2N/nwy1Qs9dpeL9/Q1fLC9QE6qv84fPV4XdNr2htoecomL5u5KRZ7XuWTUdjhYEraC8tpHrXlrLpvwyrpmVxqxhSYQECa57eZ2jX63R7vG0USazUHE2IFVVw3Me65rBn+hU2dtslhd0c0GQo1b8RrRKcY6rIEgcrlbo299XGkOCnxU2ywv8m9Bn36F+uhPuxeg0nY42DflJSVU9i59dzdaD5Tx5xWQeOGcMC0Ync+rIvswf6exXu2znEQYnRjmrd9ps6p89KEStwioLu/ZBTlSqjqhX99aH3Y3ibDXZO/oAG6GkOao0RFi001ae1wo/gaERaDRtQAsCHzQ223hvfQHnP7mCvUVVPHd1JmeMde1F+8uFql/tP7/JZsXeEuaPTHbWq688pJKHZvxU1S9Z/WQXPEUPwKwRdFekVBN+UoYqaZAwyBRKamookzxG2fv99RM01kJNsRYEmjajTUNeeHtdHv9appq6jOwXy2s3TmSqRXkIo1/tyysPAFZmIZTturwAsl6Ck+727dTTtA6HRtCNBUHVEaivcG21WJzjFBATr1D7g4JVZU9/E8uM6p3ecgg0Gi9ojcADn2w5xL3/2UrfuHBevDaTz+84yVIIGNy1IIPgIEFseAhTh5jOMzfjnnOnmgjWvRDg0fdAjgdB4N4vIClDOYsrDkFDlWs266CZcHQH1Jb5vq8/OQQajRcCKgiEEGcIIXYLIfYIIX5tcTxeCPFfIcRmIcR2IcR1gRyPvxSW1/HbD7YxYWAC79w8k3lmU48HhiRF86uFI/j5/OGu7SCLcyA8HmL6KqfgsHmw5pkAP0EPo7HO2YawO/sI3PsCJ6WrQmv7/ue6H+x+AqlCPX3hTw6BRuOFgAkCIUQw8ARwJjAaWCyEcG/oehuwQ0o5AZgL/EMIERaoMfmDzSb55bubaWiy8eilE732+HXn5lOGseRkt/BQw/ZrCJLBs6CqUGWYajqGart/ICSym2sEORAarSpbgtNEtOtT121QZaFFMOT7YR4qLwCE874aTSsJpEYwDdgjpdwnpWwA3gLcSyNKIFao5XYMUAo0BXBMPnl55QGW7ynm/rNHMSSpAxpkGM5BA6OiYUNV+++tURiO4v4ToPaYM0mru+HeL8D4u9j7LYTFqG5dBmHR6nn88ROUF6j6+iFduobSHMcEUhAMAMx6eoF9n5l/A6OAQ8BW4A4ppc39RkKIJUKILCFEVlFRUaDGS2l1A3/5YhfzR/bl8ml+xm97o75SRQ0lmWrEh9nDSuvb0YBE44ohCIy2g4bztLvhviiISlQlFprqXLVGg0EzVWlqX9pjRYHKTdBo2kggBYGVUd2tNRILgU1ACjAR+LcQokUZRCnls1LKTCllZp8+fTp+pHbW7i+locnGrXOH+fQJ+IXZUWwQbggCrRF0GIajeMBk9dod/QQNNVCe5/q3IAQkmhzH7gyaroTE4c3e761zCDTtJJCCoAAwx7Ololb+Zq4D3peKPcB+YCRdRNaBUsJCghiX2kGhnVaCwNAItGmo4zA0AiNbtzv6CUr2qFf3DmLG30aiRf17o0mLt3wCKbUg0LSbQAqCdUC6EGKI3QF8GfCx2zl5wHwAIUQyMALYF5DRHDsAG5Z6Dcdbl3uMCanxhId0UOnokhzl8Os1xLnP8BGcKBqBlMrG7d4HtzOpOqKKliUMVtm6XSkIKgutS0g7QkfdVv7mCCJ3YpNVBrK7nyB3pfPvuKZEaQ06h0DTDgImCKSUTcDPgC+BncA7UsrtQohbhBC32E/7PTBLCLEVWAbcK6Ustr5jOzm0ET7+uYrZtqC2oZntB8v97ifsF8XZ0CvN1YkXfoL5CA4sh1cvgJyvum4MVUcgJhmCQ5TDtSsFwTcPwqs/abm/ZA8gWhYdHDgdgsM8d8oaNFNFDhmC9uhOeOlM+PI3alvnEGg6gIBmFkspPwM+c9v3tOn9IeD0QI7BQZC9TaSt0fLwpvwymmySqWkd2CDe3TkIJ55p6Nh+9Zq7AjIWds0Yqo6qPA2wN0PvQh/B0R0qPLimFKLMiYXZqqREaKTr+YNnwn0FEBJufb+B02HT60qQJKXDCnvRwi3vwKm/1TkEmg6h52QWB9sFQbN1dGrWgVIApgzqII3A1uz85zVzojmLjYmoNQXSOhpDIwC7IOgijcAoMAgWbSizPdfb9yQEwNkrIG8VlOXD1ndh1Dmqd8HqJ/1rUanR+KDnCIIgu/LjQSPIyj1GRnIM8VGtbzBvSVkuNDdYaASx6vVE0QiMiejQBpXh29lICdVFrhpBxSE1KXc2RoFBcPoEwC4gLBYF/pCUrvwfeath1RNq38I/w7iLVN2qwm0qkS6qA02amh5HzxEEDo2gpSBotkk25B7rYP+APUrEXRAEh6h/3BPFR1Cerxy0zQ3KD9PZNFSpydchCAZCc72qxtnZmCd/8/uKAlVKoi2CQAilFez9H2x4BcZdDAkDVU+BxmrY/KbqQ6CbumjaQQ8SBHaHbXPL5JzdhZVU1jd1sH/ArcCYmfCYE8g0dBDSTlLv/SmH0NEYoaOGachIrOoKP4Eh/KOSnOGiYB1G3BoGTXdqG0ZTmeQxkL5Q9T/W/gFNO+k5gsDhLG7pI1ifq/wDmYM7OGIoKtFaZQ+LOTFMQ0YMe/8JKg7e37LJHYmRTGY2DYG1n6C2DN66omXmcXMTvH8zHNzg/bO+exg2v+X5eHG2Cg8ePNNNO2ivILD7CTLOhL6jnPvn3KVetSDQtJOeIwiC7T4CC9PQugPHSI4LJ7VXZItjbabqqOciYOGxqvzE8U51sTLDxA9U1TLzVne+bd4hCEzOYrAWBAezVJ/gHR+57i/cDFvegh0fev6cpgZY/gisf8XzOUaBwaQRULrfWRqiOFv1n4huY1Z8ymSYtgQWPOS6f/BMOOXXzj4GGk0b6TmCwEv4aNaBUjLTendMWQmDhio14VsRHntimIbMMeyDZkJdGRTv7twxuJuGInupCp9WgsAR4eSWqWtoMu6RPmYOb1aJW+aVvjtGuHBShjLZGKG1RsRQW/++gkPgrL9BnxEtj516n6poq9G0g54jCDyEjx4sq+VQeR1TB3egfwDUit8IFXUnLAYaTgCNwBzD7uiz28nmoaojKns70m6CE8JzLoFDEKx2zYQ2BIM3QWCcU1OscgTccRQYTHf6hRxtKHOsS0hoNN2EHigIXJ3F3+5SK8rZw5M69vMaqpzJY+6cMBqBSRD0HgrRfbtGEMT0dZZ2NsbjTSOoPupcrUvpzIE4tt/SdAhAvilPwuwIdt+XmO6sJ1ScA3UVKsGsLRFDGk0n0XMEgQfT0FfbCxmaFM3wvh4m7bbiTSMIjzkxfATlBcoME9nLHuY43f+G6x1FVVFL23v8AOtS1OUFTs3BEFil+5RgGDRTBRKU7m95nZTquQynrZV5yOwQjohTpS6Kc1S9KWO/RtNN6TmCwCKPoLy2kVV7S1gw2ncrSheqS6Cx1vs59VXOAnPuBDpqqPYYNNV7P6e+SkXJGD/VbYi7L893jWEfNFMl0lUcbv292oo5q9ggfqCa3N0T3MrzYehc5bg1BJYhECZdpV6tJvmSPaq42/hL1ILCUhBkKxNVb3uBwaR0ta+9EUMaTSfQcwSBI7PY6SP4bvdRmmyS08cke7jIgsZaeGoWfPhTz+fYmlWyjzfTUGONOi8QPDcf/vcn7+d8dBs8d6rz5+WzW/85FQddQxcHTlevB7Naf6+2UnXUQhBYRA7ZbCrjOGGQKu9sCIC8VRCRACMXqW2rSd44d/AcVTTOypdQnGMvMGgvF5GUofYV7VZ/e72HtLxGo+km9BxBYKERfL3jCEkx4Uwc2ApH8cbXlM13+wfOBCJ3jNW+R9NQAMtMSKlW5Yd8xMQXblET2+K3YeTZUJbX+s9yr4Pfe6h6bcu92oLNplb+Rg6BgWGjLzFN2NVFyj9kOLaLs5Vml79GbUcmQEw/60k+b7UyKRmOYE+mIfOqPykD6stVyeheac6/P42mG9KDBIFrZnF9UzPf7S5iwei+BAf5aRZqboKVj0PfMep+K/9lfZ7hCPYUPupoVxkAP0FjrdJ6vEXANNWr/gyDZ8GIM1QJ5MZq3+Yu93tUHXEtduYtdDMQ1B5Tz+quEZidtQZWEU67P1WTurGdlO4qPAwM/4AQaoI/dsDVqewoMGhqOmOMIX+NNgtpuj09RxC4ZRav2ltCVX0Tp4/u5/89dnyoVtun/gYmXaHqvFQWtjzPWOl7NA0FsAKpUcOo8rCKWLGidJ+qXmlMUFGJ6tUqLNITFXZnrFkjcIRudpIgcM8qNojqrRzI5pW7OechZbJdkD+u9hmdwJIy1DXm0NKqo1C6VznCjXPcncpleSqxzl0jAEDqiCFNt6cHCYIge3E0tZL7escRosKCmTks0b/rpYTlj6p/8BFnwayfqwlh9ZMtz/WpEQTQNGSe/K1Wt9CyDpIhCGpbIQg81cHvEkFg4eMxbPQG5vGGRigtqDjbtSlMUgbUlSszkoERNmpEDLnnCIC1QzhuAIRGtdyv0XRDeo4gAKUV2Bqx2SRf7zjC3BF9iAj1sy3lnmVwZKsq+hUUpOzho8+HdS+2bH9prMq9OYvN53Uk5nt68mEYk5hhvnBoBCX+f44xsRpF3gziB3SeIDAmbEtB4GbLLy9Qv4+IBLVtmINSJivBAE7Tjvm6vNUQEqHqKYEzMcx8jlWIaFCQ8/vVgkDTzelZgiA4FJqbWLO/lKOV9SwY7TaB2Gzw4yNQeaTltSseVbWDxl3i3DfnTpUhnPWi67kNPjSCQJqG6sqd7z2VQyjeoyZwYxwdKgg8hG4GAodGYFHDJylDaTjV9meqsDu2jVBXwxxkmHyMa8BNEKxSwsKIBoqIa+lULtptXWDQ0ZjerWG9RtPN6FmCICgE2dzAw1/som9sOAvHuPkHSnJg2UMti5LZbKoV4/iLXfsP958AyePUMTP1PqKGAtmu0nBAi2AvgiDb1W7dFh9Beb7KJDZW0waGqajCIqGro6k4rMwvVvka7it39wintDkwaBaMMfUXjktVvSIMTeroTji4HobPc7232ancWAe7P4fUqS3HMPo8GHOBbhqj6fb0LEEQHEZuUTmb8sv45cIRRIW5tWw2HIruK+O6MuVcje3f8p7RSRamIftkHOZJI7BPXIF0FvcdbR05JGXLUMdIe/hsqzSCg9blj71V/+xoyvNdV/lm3G357oIgIg6u/xxSJjr3BQUp85BxzYrHlKDJvMHt3ian8uY3lAY087aWYxh9Llz8cpsfT6PpLHqUIJBBIWzLL2ZU/zgunGwxiRmTl/uEaKyUoywcy5EJSlCYMQrK+TQNBcBHYDiLU6eoaBf3pLXKQjU+syAIDlG289aahrpcEHgYA6jEseBwtXJvrFX+BH/q9huTvNEfePI11iafunL1Xa74FwyY4mzOo9Ech/QoQVDZKGhoaOD+RaOscwc8CgL7tpWKH5FgoRFUqWxST03JQ8KV4zogpiG7IEiZrHImynJdj7s7ig2iEv0XBEZDGquG6Y4OYZ0gCNwzm80EBatnLM5RGcXgX4P3xHQVDvrjP9S21UrfcCr/+HdVqG72nbpVpOa4pscIgpKqekpqbQyIDfFcadSYvNzDKI0JMtJCEBgagTn23Kg86m1yCFS7yroKZZLqM1Jtu5uHPBVBa40gqD2mEtCsJuGQcBXFUxFgQWCV0OaOETlkmPzcHduerkHC+ped/YFbnGP/7ta9oATHyDaU59BouhE9RhAs31NMI8GMSY7wfJJPjcDCNBSRoPIJGqqd++orPZuFDMJjA6cRRMRZx7uDEgyh0RDn1j2tNYLAEZPvYWKN64QQUquENneMLODSfb7PNV8DgHT2B3bHcCojYfbtriWwNZrjkB7zF3zexAEMSe5FjLeSLw5B4KYR1PrwEYCrn8AfQRAWoHaVdeXKGR3VWzVRd9cIjIghd20lKtH/qCHD3ORpYvWVVPbcfFj7nH+f5QlP4atmktKVk3//D4BoKfysSByuEg/d+wObCQpS947tD+MvbfXQNZruRojvU04cQkPDPDcesdmcq8yaEmXqMSbLmhLleAyLbnmdEXFTW+acGL01pTEIVE8CQyOAltm1oLaNLFkzUb1bPrcnDq5XPo4+HibK+IGw5xvre0mprg+NhGk3+fdMVnjKbDZjaEX7vlPmKk8+GzNhUXDZG84EMk+c85h69eeeGk03p8doBIAjs9gSR3XKgao3bWON81hNiVoxW02QEZ40Ah+CIFA9CeoqnOGp5lBIUOar8nzr2jdRiS2f2xN5q9VEGRZlfTw+Vd2n9ljLYw3VgISCLGdz97bgj0Zg5BLUHvPPLGQw4kzf2sOAyepHozkB6FmCwJ5ZbIkxsRgrQbO9vKbU2iwETtOQOXKo3h+NIECmIXeNwNxj12inaCkI7I5wX36CpnrVyMYo0WCFI4TUom+wIfyaalUp7LbiKaHNTHiMU1C0RhBoND2MniUIgkJa9Cx2YExa/carVxdBUOI5O9TQCMyr3wYv3ckMAhk1FG4SBOA0D3nrluVvmYlDm1SlTSvzkoG3XAKz8GtPf2NPCW3uGEJPCwKNxiM9SxAEh3k2DTk0Ak+CwIdGUOemEfg0DQU4agick2CJWRAI6D2s5XX+CgKjxePA6Z7PMUI6fQqCdvQ39pZMZsYQev7kEGg0PZQeJgi8mIYqDqqwSmOSNEfQeBMEYbEqysQwDUmpMnf9NQ0Z+QcNNbDzE9d8BFCZwds/9OzkNtNYpzQeQyNIGKyE37b/wKonIecrlXFrZU5xCAKTZlNdAjnfuJ6Xt1pF1lgVejOITlLOdW+mofhB6l7uz+sP3hLa3EnUGoFG4wufgkAIcbYQ4sQQGEEhXjQCe92aaHuymSEImpvUJO9JEAQFqWbohkbQWKNCFn3mEcQA0pl/sPUdePsKyP7C9bxNb8C710D2lz4fz7Hajoi3jy1Yrdz3fgtf3qfaV3oy6VhpBGufgdcvVOYgUJFVRmtHbwhhL0dtUXjOMIeln6b8FyV7fT+XO94S2twZPFMJ635jW/85Gk0PwZ8J/jIgRwjxVyGEh3jB44TgUM8ra8PUEBGvVvjGhFhXBkjvFSTNZSZ8VR41cK9AWrRbvS5/1HmOzaYKnwEU7/Z+P3CWlzD7J67+CO7Ndf6c/5SHZ3B7boCiXerVGENJjsqp8OYfMPCUS2AIq+EL1Gt+G/wEvhLazPQbB78pUH2DNRqNJT4FgZTySmASsBd4SQixSgixRAjhY8kLQogzhBC7hRB7hBC/9nDOXCHEJiHEdiHE961+gtYQ5IcgCApWuQHGhOgtq9jAXHjOV+VRA0dzGrsgMMI881dDrt12vvtTN/u+D4xeBBEmQRAUrMZn/HjKgnV/bvNn7vhQZec6/AM+NAJQZhsrQWAU5BswWZXsaIufwJ8cAo1G4zd+mXyklBXAf4C3gP7ABcAGIcTPPV0jhAgGngDOBEYDi4UQo93OSQCeBM6VUo4BLm7LQ/hNsIc8Akd1SrvN2VxuwVvBOQOzRuCoPOqHj8B8fnE2jFikJscVj9pbY/5TrWTTTvLcW8CMlUbQGszPbTRkH3+pMqmtfFzZ9KOSINHC2exOfKrqm+wueM1tPAdOb1vkkEMQaAewRtMR+OMjOEcI8QHwLRAKTJNSnglMAH7p5dJpwB4p5T4pZQNKiJznds7lwPtSyjwAKeXRNjyD/3gyDTmqU9pNDZaCwF+NwEd3MgPDNFRfqRzFZfmqNv70W5SfYO1zKgN31u2q1EFxjm/HqlGCOqIDBEFZrnI8p50EEy+Hja8rX8OgGf5V2oxPBaTzuzWor1QmqNAoda+SPVBVZHkLj1QUKGd0lIfigRqNplX4oxFcDPxTSjleSvk3Y7KWUtYA13u5bgBgDhspsO8zkwH0EkJ8J4RYL4S4uhVjbz1BoapAnDtGdIthajDX3fFHELj4CAzTkB8lJkAJjtK9gFTRONNuUtFLn98D0X3UJJyYrlb7VRYtNM04NAKfVjtrzM9dbEo+m3W7EgpVR/zzD4DnXIKGKnuklXDeq7V+gvICJbR1sTeNpkPw5z/pAWCtsSGEiBRCpAFIKZd5uc5q2ei+pA0BpgCLgIXA74QQLbKd7D6JLCFEVlFRK1ePZoJDrDWCcrdKlkbdHXBOjFYlqA3Mpah99Ss2MHwIDVVOs09ShvrsKdeo7em3qJo8jkqiPvwEde01DZme2zymxGGq2xb4jhgyiPMgCMw5FikT1cr+gFurT4Dv/wrfPGR9b39zCDQajV/4IwjeBWym7Wb7Pl8UAGYjbipwyOKcL6SU1VLKYuAHlMnJBSnls1LKTCllZp8+XuLXfeGp1pB73RrDRCKleg2N8lxXB1xLURsagT9lqEGt4o1EL8P2ftLdMPNnMG2J2rZqqm5FR/kIpFSfZW7IftpDMOcXkDLJv3sZeQY1xa77zTkWIeGQcbpq92hONCsvUIJgxaPW4aX+5hBoNBq/8EcQhNht/ADY34d5Od9gHZAuhBgihAhDhaF+7HbOR8BJQogQIUQUMB3Y6d/Q20BwmJqw3W3t5fmu1SmjEpXAqK/0XmfIwKhAWlfm1AhaYxoqzrEnekWqfdFJsPCPTlt/XIoyF/mjEYRGK82nLZif272vce8hcNoDKrrIH8LjAWHdz9nsSJ99p4p2Wv+Kc9+qJ1UuhuGkNtPcqJzQWiPQaDoMfwRBkRDiXGNDCHEeUOzlfACklE3Az4AvUZP7O1LK7UKIW4QQt9jP2Ql8AWxBmZ+el1Jua/1j+IkxQbqbh9xNDYYZqLbUe50hx/mmwnP1lYCwLlltJjRKOU0N05BV/R8DIZzdtrxRX952RzE4n7umRIWtWhWn85egIDUW937O9VWu2lJqpnJIr3pCVSOtKbV3B7sIJl6hEuoqTb6RysNKSGhBoNF0GP4sHW8BXhdC/Btl988H/HLqSik/Az5z2/e02/bfgL/5Ndr2EmTvSmNrxEWpKS9wbUJizrL1Vl7CwFyK+VltmgAAHGBJREFU2qg86iuyRgjlJ6irUJEzaXO8n5+UDnlrvJ9jLjjXFoznLNmrwmkT2yEIwLqfc0MVxPR13Tf7TpXBvPVdVeqjsVp1BwuJgA2vwJqn4LQH1bn+lJ/WaDStwp+Esr1SyhmoXIDRUspZUso9gR9aAAi2CwKzRmBVt8YhCOwagTdHMbhqBA1+dCczCI9R2buNNb5X30kZyoTV4KVfgLngXFswntuI4vGmpfhDZELLngRW3duGz4fkcSpvYs3TkL4QksfYndTnqd7ARrKcw7GvfQQaTUfhV/ydEGIR8FPgLiHE/xNC/L/ADitAODQCUwhpTamqjW82NZhr8/vjI3DRCPxoSmMQFuOs4+Nr0jWaqpeanKel+1yFWrs1AvtzG0le7TENgfpeWpiGLASBEDDnTmWOqimBOXc5j82+Uwm47/4C+76H3OVqvz/lJTQajV/4k1D2NHAp8HOUaehiYHCAxxUYHBqBqSdB5WH1Gtffuc+Y+CsLld3dp7PY7CPwoymNQXiMuj/4IQjcIoeKdsPjmbBhqfOc+sqO0QgKspRjPaGdv+bIXq6mISO81ur7GX0+9B4Kg2apQnEGKRNh2DxY/SQsPVf5D+IG+PbBaDQav/HHRzBLSjleCLFFSvmQEOIfwPuBHlhAsDINNdaq11DTxBIRDyLYWefHl7PYKEVtRA35bRqKdX5etI+w2N7DAOGMHFrxL5DNULjVeU59OzUC47mbalU/4rZGHxlEumkETfVKG7PSmIJD4IavVaSQOxe9BEe2O7cTBrVvXBqNxgV//tPr7K81QogUoAQYErghBRAr01BzvXo1NyEXQq2OjUnXl0ZglKI2NAJfk7qBsTJOTPftXA6NUBNgcbayk295W+03h5TWtdNHYDx39VHV77i9GM5io4m9r4J80R5KRkQmQNrs9o9Ho9FY4o+P4L/24nB/AzYAB4A3AzmogGEVPtpkl3NmQQB2QZDtfO8Lwx5e70dTGgNDI/DXKZuUoca02h5nP+QU5xibG9VKPjzev3t5wnjW9jqKQU3gtkblDAdTQb42lsDQaDQBwatGYG9Is0xKWQb8RwjxCRAhpSzvlNF1NC7ho3aa7P4CK0FQtNP53heRCaaooVY4i8F/p2xSBhz4EUr2wdgLVbOV/d+ryBybPfm7PRoBdKwgiDD5TsKi/e/VoNFoOhWvGoGU0gb8w7Rdf9wKAbB2FhsaQbC7IDD5BfzVCGqPtUyY8karNYJ0Nd7GahVl43Ag73E6ndvjIwDnc7c3Ygha9nP2tyCfRqPpVPwxDX0lhLhQCH9qD3dzHILA7CPwohE43vtwFoOa9KqOKm2jNVFD0DrTEED66SrO3hxJ1N4S1AbGc7c3mQxcNQIwFeRr5xg1Gk2H4o+z+BdANNAkhKhDhZBKKeXx999saRqycBaDc/IPi215zIqIBJUVC/5rBEPnQuE2FTbpDykTVYvHeb9T2wmD1TMVZ0OCPcGqvZPsiLMA2X6BAp41Am0a0mi6FT4FgZTyxPHsWYWPOgRBhOu5xso4qpd/945MUOGc4L9GMGAKXPySf+eCsrNf+Z5zOzhEZd+W7IHUqWpfeyfwjNPVT0fgSSPQpiGNplvhUxAIIU622i+l/KHjhxNgvIWPBrsVVHUIAj/8A+CsQAqdGxWTOFxpBO0tQR0ItEag0RwX+GMausf0PgLVgnI9MC8gIwokjvBRC2exR43AT0FgrH6hcye6pAzV2tJoKBPRzvDRjsS9FHW91gg0mu6IP6ahc8zbQoiBwF8DNqJAYqz6my3CRw2zkYHhI/BbIzAJAk8JU4EgKUNpOIe3qO3uFKPvXoq6oUplcPvb00Cj0XQKbWn6WgCM7eiBdApWpqGmOhU66h4U1S6NoJMFAcDBLAiJbCnQuhqXfs4V2iyk0XRD/PERPI6z13AQMBHYHMhBBQyrzOLmhpZmIYCoJFV3JybZv3tHdpVpyF4KonSf/2PtTMz1hlpTkE+j0XQa/vgIskzvm4A3pZQW3caPAyzDR+sgxKLzZngMXPMxJPup/Jg1gs6c7CLiIaYfVBV2L0exgVkjaE1BPo1G02n4IwjeA+qkVLGRQohgIUSUlNJLh5RuimVmsQeNAHx3DTMT2UWCAFQWcFVhx8T+dzSRvZylvluTda3RaDoNf3wEy4BI03Yk8E1ghhNgHM5it/BR99DRtmCUog6Nan/55tZilIPojhpBpNlH0IqCfBqNptPwZ8aKkFJWGRtSyiohRFQAxxQ4jFr37pnFnjSCVt3bXoo6qAuctYbDuDtqBEZVVilb18ZTo9F0Gv5oBNVCiMnGhhBiClAbuCEFEE+ZxVY+grYQkdA1UTHdXSNoblANgOqrdNSQRtMN8UcjuBN4VwhxyL7dH9W68vjDU/hoR2gEYC8zYeuYe7UGh0bQjZLJDNz7OWvTkEbT7fAnoWydEGIkMAJVcG6XlLLRx2XdEyORyews9hQ+2hYGzXS9d2cRlwr9J0D/iZ3/2b4wnOjVRcofo01DGk23w588gtuA16WU2+zbvYQQi6WUTwZ8dB2NEMox7N6hzBz62R7O+HPH3Ke1BAXBzd209JPx3Za3sjKrRqPpNPzxEdxk71AGgJTyGHBT4IYUYIJC3UxDDR3nI9C0xNAIyvPVqzYNaTTdDn8EQZC5KY0QIhg4fmfO4JCWGkFHmYY0LTE0grI89aqdxRpNt8MfZ/GXwDtCiKdRpSZuAT4P6KgCSVCoa/hoc0PLNpWajsOhERSoV20a0mi6Hf4IgnuBJcCtKGfxRlTk0PFJcGjLMtT+dCDTtA2jFLXDNKQFgUbT3fBpGrI3sF8N7AMygfnAzgCPK3AEh7pmFjc1aEEQSIxS1A6NQJuGNJruhkeNQAiRAVwGLAZKgLcBpJSnds7QAkQL01C9FgSBJiIBynLVe+0s1mi6Hd40gl2o1f85Uso5UsrHgebOGVYACQ51OottNu0j6Awiu6hXg0aj8QtvguBCoBD4nxDiOSHEfJSP4PjGHD5q+Ap0+Ghg6ap+zhqNxi88CgIp5QdSykuBkcB3wF1AshDiKSHE6Z00vo4nOMQpADz1K9Z0LEYIaXB49+ugptFo/HIWV0spX5dSng2kApuAXwd8ZIHCnFlsCISOKEOt8YxhGtKOYo2mW9KqnsVSylIp5TNSynn+nC+EOEMIsVsIsUcI4VF4CCGmCiGahRAXtWY8bcJsGtIaQedgaATaLKTRdEva0rzeL+wZyE8AZwKjgcVCiNEeznsYlbgWeMyZxU2Gj0A7iwOKoRHoHAKNplsSMEEATAP2SCn3SSkbgLeA8yzO+znwH+BoAMfixBw+6tAItCAIKBHaNKTRdGcCKQgGAPmm7QL7PgdCiAHABcDT3m4khFgihMgSQmQVFRW1b1Tm8NHmevs+LQgCSqQ2DWk03ZlACgKrUFPptv0ocK+U0mt+gpTyWSllppQys0+fPu0bVZDZNGQXBFojCCyGRqCTyTSabkkgu6wXAANN26nAIbdzMoG37MVNk4CzhBBNUsoPAzaq4DCTaUgLgk5BRw1pNN2aQAqCdUC6EGIIcBBVruJy8wlSyiHGeyHEy8AnARUC4FprqFk7izuFCO0s1mi6MwETBFLKJiHEz1DRQMHAi1LK7UKIW+zHvfoFAkZQSEtnsfYRBBbtI9BoujWB1AiQUn4GfOa2z1IASCmvDeRYHJjLUDvCR3UeQUCJSICpN0HGwq4eiUajsSCggqBbEmQyDTnCR3VmcUARAhb9vatHodFoPBDIqKHuSbApj8AIH9UagUaj6cH0TEHgHj6qaw1pNJoeTM8TBEZmsZQ6fFSj0WjoiYLAKINsazJpBFoQaDSankvPEwRBdv94c6PyEQSFqr66Go1G00PpeTOg4Q+wNSqNQDuKNRpND6cHCgK7aajZbhrSoaMajaaH0/MEgWEastlNQ1oj0Gg0PZyeJwgcGkGD0gh06KhGo+nh9DxBEGQIAu0j0Gg0GuiJgsA9fFT7CDQaTQ+n5wqCZu0j0Gg0GuiJgsAwDRnho9pHoNFoejg9TxAEax+BRqPRmOl5gsCcWdxUr+sMaTSa/9/evQdHVeUJHP/+aB6R50IGZxkiJroKEpImIaDC8hoFEVjFIAWpGQsIOoXuOq4uPhFhZCxnC2pVBNdCBxxdMD5hwUIdkwVxCzVkHN4QAckuWQRDwBAxQIK//aNv2iZ2E0LSNOnz+1R1pe+5jz4/Otxfzrn33OM89xJB6Mji05YIjDHGwURQZ2SxPXDOGOM49xJB6Mhiu33UGGMcTAShI4vt9lFjjHEwEdQdWWy3jxpjHOdeIvjJyGJrERhj3OZuIqj+HlC7RmCMcZ57iaC2a+jkd4Gf1iIwxjjOvURQ2yI45SUCu33UGOM49xJB7e2jwRaBJQJjjNvcSwS1dwmdskRgjDHgZCKo0zVkicAY4zj3EkHdriG7RmCMcZx7iUAkkAxOHQ8sW4vAGOM49xIBBG4hPVUZeG+JwBjjODcTga9VSIvAxhEYY9zmbiIIXiOwkcXGGLdFNRGIyCgRKRaRPSLySJj1vxKRLd5rg4j4o1mfoBat7K4hY4zxRC0RiIgPWATcDPQGckSkd53N9gFDVTUdmAssjlZ9zuCzRGCMMbVaRvHYA4A9qvoVgIjkAbcCO2o3UNUNIdt/BiRFsT4/ahEStt0+aky9qqurKS0t5cSJE7GuiqlHQkICSUlJtGrV6pz3iWYi6A7sD1kuBa49y/bTgPfDrRCR3wC/AejRo0fja+YL+QeyFoEx9SotLaVDhw4kJycjIrGujolAVSkvL6e0tJSUlJRz3i+a1wjC/bZo2A1FhhNIBA+HW6+qi1U1S1Wzunbt2viahV4gtkRgTL1OnDhBYmKiJYGLnIiQmJjY4JZbNFsEpcBlIctJwIG6G4lIOvAycLOqlkexPj+yriFjGsySQPNwPt9TNFsEG4GrRCRFRFoDk4BVoRuISA/gXeAOVf0yinU5U23XkPjAF81caIwxF7+onQVVtUZE/gn4EPABS1R1u4hM99a/CDwBJAIveFmsRlWzolWnoNrJaWwwmTHGRLVrCFVdA6ypU/ZiyPs7gTujWYewalsBNk2lMc1CeXk5N9xwAwAHDx7E5/NRe72wsLCQ1q0j/18uKiri1VdfZcGCBRekrs2Rm/0itReLrUVgTIP9bvV2dhw41qTH7P2Ljsz+h9SI6xMTE9m0aRMAc+bMoX379syYMSO4vqamhpYtw5/OsrKyyMqKfkdDc+bmIyZqu4bs8RLGNFtTpkzhgQceYPjw4Tz88MMUFhYycOBAMjIyGDhwIMXFxQCsW7eOsWPHAoEkkpuby7Bhw7jiiivqbSWMGzeOfv36kZqayuLFP453/eCDD8jMzMTv9wdbKt999x1Tp04lLS2N9PR03nnnnShF3vQcbRHUdg1Zi8CYhjrbX+4X2pdffkl+fj4+n49jx46xfv16WrZsSX5+Po899ljYk/GuXbtYu3YtlZWV9OzZk7vvvjvi4KslS5bQpUsXqqqq6N+/P+PHj+eHH37grrvuYv369aSkpHDkyBEA5s6dS6dOndi6dSsAR48ejV7gTczNRBC8WGwtAmOaswkTJuDz+QCoqKhg8uTJ7N69GxGhuro67D5jxoyhTZs2tGnThksvvZRDhw6RlBT+oQYLFixgxYoVAOzfv5/du3dTVlbGkCFDggO2unTpAkB+fj55eXnBfTt37txkcUabm11DPrtryJh40K5du+D7WbNmMXz4cLZt28bq1asjDqpq0+bHsUM+n4+ampqw261bt478/Hw+/fRTNm/eTEZGBidOnEBVw96rH6m8OXA7EdhgMmPiRkVFBd27dwfglVdeaZLjde7cmbZt27Jr1y4+++wzAK6//no+/vhj9u3bBxDsGho5ciQLFy4M7t+cuobcTATWNWRM3HnooYd49NFHGTRoEKdPn2708UaNGkVNTQ3p6enMmjWL6667DoCuXbuyePFisrOz8fv9TJw4EYDHH3+co0eP0qdPH/x+P2vXrm10HS4UUQ37+J+LVlZWlhYVFTXuIGsehMLF0HM05LzeNBUzJo7t3LmTa665JtbVMOco3PclIn+JNGDX7RaB3T5qjDGO3jVkt48aYzyho5ZDFRQUkJiYGIMaXXiOJoLakcXWIjDGdaGjll3ldteQtQiMMcbRRFDbNWTXCIwxxtFEYC0CY4wJcjMRBEcW24AyY4yxRGCMuegNGzaMDz/88IyyZ599lnvuuSfi9rXjjUaPHs233377k23mzJnD/Pnzz/q5K1euZMeOHcHlJ554gvz8/IZW/6Ln5l1DLewRE8act/cfgYNbm/aYf5sGN/8h4uqcnBzy8vK46aabgmV5eXnMmzev3kOvWbOm3m0iWblyJWPHjqV3794APPnkk+d9rIuZtQiMMRe922+/nffee4+TJ08CUFJSwoEDB1i+fDlZWVmkpqYye/bssPsmJydz+PBhAJ566il69uzJjTfeGJyvAOCll16if//++P1+xo8fz/fff8+GDRtYtWoVDz74IH379mXv3r1MmTKFt99+GwiMM8jIyCAtLY3c3Nxg3ZKTk5k9ezaZmZmkpaWxa9euiHFFmkPh9OnTzJgxIzi3wfPPPw/Axo0bGThwIH6/nwEDBlBZWdnIf1mPqjarV79+/bTRNr+pOruj6l+XNf5Yxjhgx44dsa6Cjh49WleuXKmqqk8//bTOmDFDy8vLVVW1pqZGhw4dqps3b1ZV1aFDh+rGjRtVVfXyyy/XsrIyLSoq0j59+ujx48e1oqJCr7zySp03b56qqh4+fDj4OTNnztQFCxaoqurkyZP1rbfeCq6rXa6qqtKkpCQtLi5WVdU77rhDn3nmmeDn1e6/aNEinTZtWsSYKioqtLq6WlVVP/roI83OzlZV1RdeeEGzs7OD68rLy/XkyZOakpKihYWFP9m3rnDfF1CkEc6rjrYIakcWW4vAmOaitnsIAt1COTk5vPnmm2RmZpKRkcH27dvP6M+v65NPPuG2226jbdu2dOzYkVtuuSW4btu2bQwePJi0tDSWLVvG9u3bz1qX4uJiUlJSuPrqqwGYPHky69evD67Pzs4GoF+/fpSUlEQ8TkVFBRMmTKBPnz7cf//9wc/Nz89n+vTpwek3u3TpQnFxMd26daN///4AdOzYMeL0nA3lZiKwawTGNDvjxo2joKCAL774gqqqKjp37sz8+fMpKChgy5YtjBkzJuIcBLUizRcwZcoUFi5cyNatW5k9e3a9x9F6HtZZO+fB2eY7gMhzKGiYuQ3ClTUVNxNB8BETlgiMaS7at2/PsGHDyM3NJScnh2PHjtGuXTs6derEoUOHeP/998+6/5AhQ1ixYgVVVVVUVlayevXq4LrKykq6detGdXU1y5YtC5Z36NAhbD98r169KCkpYc+ePQC89tprDB06tMExRZpDYeTIkbz44ovBJHLkyBF69erFgQMH2LhxY7DOZ0syDeFoIrCLxcY0Rzk5OWzevJlJkybh9/vJyMggNTWV3NxcBg0adNZ9MzMzmThxIn379mX8+PEMHjw4uG7u3Llce+21jBgxgl69egXLJ02axLx588jIyGDv3r3B8oSEBJYuXcqECRNIS0ujRYsWTJ8+vcHxRJpD4c4776RHjx6kp6fj9/tZvnw5rVu35o033uDee+/F7/czYsSIelsu58rN+QhOHYd1T8PwmdDqkqapmDFxzOYjaF4aOh+Bm+MIWreDkb+PdS2MMeai4GYiMMaYC2jp0qU899xzZ5QNGjSIRYsWxahGZ7JEYIw5J9G8ayXeTZ06lalTp16Qzzqf7n43LxYbYxokISGB8vLy8zrJmAtHVSkvLychoWFPVrYWgTGmXklJSZSWllJWVhbrqph6JCQkkJSU1KB9LBEYY+rVqlUrUlJSYl0NEyXWNWSMMY6zRGCMMY6zRGCMMY5rdiOLRaQM+J/z3P1nwOEmrE5z4WLcLsYMbsbtYszQ8LgvV9Wu4VY0u0TQGCJSFGmIdTxzMW4XYwY343YxZmjauK1ryBhjHGeJwBhjHOdaIlgc6wrEiItxuxgzuBm3izFDE8bt1DUCY4wxP+Vai8AYY0wdlgiMMcZxziQCERklIsUiskdEHol1faJBRC4TkbUislNEtovIfV55FxH5SER2ez87x7quTU1EfCLyVxF5z1t2Iea/EZG3RWSX951f70jc93u/39tE5HURSYi3uEVkiYh8IyLbQsoixigij3rntmIRuamhn+dEIhARH7AIuBnoDeSISO/Y1ioqaoB/UdVrgOuAf/TifAQoUNWrgAJvOd7cB+wMWXYh5ueAD1S1F+AnEH9cxy0i3YHfAlmq2gfwAZOIv7hfAUbVKQsbo/d/fBKQ6u3zgnfOO2dOJAJgALBHVb9S1VNAHnBrjOvU5FT1a1X9wntfSeDE0J1ArH/yNvsTMC42NYwOEUkCxgAvhxTHe8wdgSHAHwFU9ZSqfkucx+1pCVwiIi2BtsAB4ixuVV0PHKlTHCnGW4E8VT2pqvuAPQTOeefMlUTQHdgfslzqlcUtEUkGMoDPgZ+r6tcQSBbApbGrWVQ8CzwE/BBSFu8xXwGUAUu9LrGXRaQdcR63qv4fMB/4X+BroEJV/0ycx+2JFGOjz2+uJIJw8+vF7X2zItIeeAf4Z1U9Fuv6RJOIjAW+UdW/xLouF1hLIBP4d1XNAI7T/LtD6uX1i98KpAC/ANqJyK9jW6uYa/T5zZVEUApcFrKcRKA5GXdEpBWBJLBMVd/1ig+JSDdvfTfgm1jVLwoGAbeISAmBLr9fish/EN8xQ+B3ulRVP/eW3yaQGOI97huBfapapqrVwLvAQOI/bogcY6PPb64kgo3AVSKSIiKtCVxYWRXjOjU5Ccws/kdgp6r+W8iqVcBk7/1k4D8vdN2iRVUfVdUkVU0m8L3+l6r+mjiOGUBVDwL7RaSnV3QDsIM4j5tAl9B1ItLW+32/gcC1sHiPGyLHuAqYJCJtRCQFuAoobNCRVdWJFzAa+BLYC8yMdX2iFOPfE2gSbgE2ea/RQCKBuwx2ez+7xLquUYp/GPCe9z7uYwb6AkXe970S6OxI3L8DdgHbgNeANvEWN/A6gWsg1QT+4p92thiBmd65rRi4uaGfZ4+YMMYYx7nSNWSMMSYCSwTGGOM4SwTGGOM4SwTGGOM4SwTGGOM4SwTG1CEip0VkU8iryUbsikhy6BMljbkYtIx1BYy5CFWpat9YV8KYC8VaBMacIxEpEZF/FZFC7/V3XvnlIlIgIlu8nz288p+LyAoR2ey9BnqH8onIS94z9f8sIpfELChjsERgTDiX1Okamhiy7piqDgAWEnjqKd77V1U1HVgGLPDKFwAfq6qfwHOAtnvlVwGLVDUV+BYYH+V4jDkrG1lsTB0i8p2qtg9TXgL8UlW/8h7ud1BVE0XkMNBNVau98q9V9WciUgYkqerJkGMkAx9pYHIRRORhoJWq/j76kRkTnrUIjGkYjfA+0jbhnAx5fxq7VmdizBKBMQ0zMeTnp977DQSefArwK+C/vfcFwN0QnFO544WqpDENYX+JGPNTl4jIppDlD1S19hbSNiLyOYE/onK8st8CS0TkQQKzhk31yu8DFovINAJ/+d9N4ImSxlxU7BqBMefIu0aQpaqHY10XY5qSdQ0ZY4zjrEVgjDGOsxaBMcY4zhKBMcY4zhKBMcY4zhKBMcY4zhKBMcY47v8BBSNIubAIQ6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Train_acc\",\"Validation_acc\"])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Train_loss\",\"Validation Loss\"])\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
