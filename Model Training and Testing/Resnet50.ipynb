{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"../input/chest-xray-covid19-pneumonia/Data/train\"\n",
    "test_dir=\"../input/chest-xray-covid19-pneumonia/Data/test\"\n",
    "\n",
    "TRAIN_COVID_PATH = \"../input/chest-xray-covid19-pneumonia/Data/train/COVID19\"\n",
    "TRAIN_NORMAL_PATH = \"../input/chest-xray-covid19-pneumonia/Data/train/NORMAL\"\n",
    "TRAIN_PNE_PATH = \"../input/chest-xray-covid19-pneumonia/Data/train/PNEUMONIA\"\n",
    "\n",
    "\n",
    "VAL_NORMAL_PATH = \"../input/chest-xray-covid19-pneumonia/Data/test/NORMAL\"\n",
    "VAL_PNEU_PATH = \"../input/chest-xray-covid19-pneumonia/Data/test/PNEUMONIA\"\n",
    "VAL_COVID_PATH = \"../input/chest-xray-covid19-pneumonia/Data/test/COVID19\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=1/255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5144 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_generator = generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COVID19': 0, 'NORMAL': 1, 'PNEUMONIA': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_generator.class_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1288 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "validation_generator = generator.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying RESNET-50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "stepsperepoch=9\n",
    "validationsteps=1\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=100)\n",
    "mc = ModelCheckpoint(\"own.h5\", monitor='val_loss',save_best_only=True, mode='min',verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_t = Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=3,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 3)            6147        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.0582 - accuracy: 0.6146\n",
      "Epoch 00001: val_loss did not improve from 0.88778\n",
      "9/9 [==============================] - 15s 2s/step - loss: 1.0582 - accuracy: 0.6146 - val_loss: 1.4505 - val_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9136 - accuracy: 0.6528\n",
      "Epoch 00002: val_loss did not improve from 0.88778\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.9136 - accuracy: 0.6528 - val_loss: 1.7093 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9275 - accuracy: 0.6840\n",
      "Epoch 00003: val_loss improved from 0.88778 to 0.76584, saving model to own.h5\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.9275 - accuracy: 0.6840 - val_loss: 0.7658 - val_accuracy: 0.7188\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7644 - accuracy: 0.7083\n",
      "Epoch 00004: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.7644 - accuracy: 0.7083 - val_loss: 132.9286 - val_accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9225 - accuracy: 0.6701\n",
      "Epoch 00005: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.9225 - accuracy: 0.6701 - val_loss: 7.2580 - val_accuracy: 0.7188\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.7153\n",
      "Epoch 00006: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.6762 - accuracy: 0.7153 - val_loss: 775.0939 - val_accuracy: 0.6875\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.7222\n",
      "Epoch 00007: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.6452 - accuracy: 0.7222 - val_loss: 239.2310 - val_accuracy: 0.6250\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.7708\n",
      "Epoch 00008: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.5190 - accuracy: 0.7708 - val_loss: 162.1231 - val_accuracy: 0.7188\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.7431\n",
      "Epoch 00009: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6233 - accuracy: 0.7431 - val_loss: 18.9567 - val_accuracy: 0.6875\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8125\n",
      "Epoch 00010: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4979 - accuracy: 0.8125 - val_loss: 10.9790 - val_accuracy: 0.5938\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.8194\n",
      "Epoch 00011: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4160 - accuracy: 0.8194 - val_loss: 14.3919 - val_accuracy: 0.7188\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.8403\n",
      "Epoch 00012: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.4780 - accuracy: 0.8403 - val_loss: 36.6212 - val_accuracy: 0.5938\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.8993\n",
      "Epoch 00013: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3256 - accuracy: 0.8993 - val_loss: 9.6257 - val_accuracy: 0.7188\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8299\n",
      "Epoch 00014: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4430 - accuracy: 0.8299 - val_loss: 5.5639 - val_accuracy: 0.6562\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8750\n",
      "Epoch 00015: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3518 - accuracy: 0.8750 - val_loss: 3.0655 - val_accuracy: 0.6250\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.8368\n",
      "Epoch 00016: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4484 - accuracy: 0.8368 - val_loss: 8.6728 - val_accuracy: 0.3438\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.8229\n",
      "Epoch 00017: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4157 - accuracy: 0.8229 - val_loss: 52.7604 - val_accuracy: 0.6562\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.8681\n",
      "Epoch 00018: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3014 - accuracy: 0.8681 - val_loss: 65.8867 - val_accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8889\n",
      "Epoch 00019: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3731 - accuracy: 0.8889 - val_loss: 3.2755 - val_accuracy: 0.6875\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.8924\n",
      "Epoch 00020: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3435 - accuracy: 0.8924 - val_loss: 1.1214 - val_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.8750\n",
      "Epoch 00021: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3543 - accuracy: 0.8750 - val_loss: 11.2758 - val_accuracy: 0.5625\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8715\n",
      "Epoch 00022: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3293 - accuracy: 0.8715 - val_loss: 1.9550 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.9132\n",
      "Epoch 00023: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2314 - accuracy: 0.9132 - val_loss: 3.3496 - val_accuracy: 0.6875\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8750\n",
      "Epoch 00024: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3548 - accuracy: 0.8750 - val_loss: 1.5206 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9167\n",
      "Epoch 00025: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2075 - accuracy: 0.9167 - val_loss: 1.1937 - val_accuracy: 0.6875\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.9028\n",
      "Epoch 00026: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2957 - accuracy: 0.9028 - val_loss: 2.0213 - val_accuracy: 0.6562\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.8958\n",
      "Epoch 00027: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2668 - accuracy: 0.8958 - val_loss: 1.0070 - val_accuracy: 0.7812\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9271\n",
      "Epoch 00028: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2320 - accuracy: 0.9271 - val_loss: 1.4007 - val_accuracy: 0.7188\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.8750\n",
      "Epoch 00029: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3688 - accuracy: 0.8750 - val_loss: 1.7443 - val_accuracy: 0.6562\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9028\n",
      "Epoch 00030: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2676 - accuracy: 0.9028 - val_loss: 1.7710 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8854\n",
      "Epoch 00031: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2717 - accuracy: 0.8854 - val_loss: 1.6430 - val_accuracy: 0.7188\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.8819\n",
      "Epoch 00032: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2767 - accuracy: 0.8819 - val_loss: 2.3879 - val_accuracy: 0.6562\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9214\n",
      "Epoch 00033: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2451 - accuracy: 0.9214 - val_loss: 2.1575 - val_accuracy: 0.7188\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9062\n",
      "Epoch 00034: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2305 - accuracy: 0.9062 - val_loss: 2.8363 - val_accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9062\n",
      "Epoch 00035: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2279 - accuracy: 0.9062 - val_loss: 1.7947 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.9271\n",
      "Epoch 00036: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2306 - accuracy: 0.9271 - val_loss: 2.0336 - val_accuracy: 0.6562\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9306\n",
      "Epoch 00037: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1907 - accuracy: 0.9306 - val_loss: 1.8773 - val_accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9271\n",
      "Epoch 00038: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1906 - accuracy: 0.9271 - val_loss: 2.4357 - val_accuracy: 0.5938\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9062\n",
      "Epoch 00039: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2849 - accuracy: 0.9062 - val_loss: 1.3427 - val_accuracy: 0.6562\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.8854\n",
      "Epoch 00040: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2408 - accuracy: 0.8854 - val_loss: 1.5153 - val_accuracy: 0.7188\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9375\n",
      "Epoch 00041: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1772 - accuracy: 0.9375 - val_loss: 1.6920 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.9167\n",
      "Epoch 00042: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2105 - accuracy: 0.9167 - val_loss: 2.5028 - val_accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9410\n",
      "Epoch 00043: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1757 - accuracy: 0.9410 - val_loss: 1.7675 - val_accuracy: 0.6250\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9306\n",
      "Epoch 00044: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1947 - accuracy: 0.9306 - val_loss: 1.2622 - val_accuracy: 0.7188\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9514\n",
      "Epoch 00045: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1879 - accuracy: 0.9514 - val_loss: 1.4729 - val_accuracy: 0.6875\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9306\n",
      "Epoch 00046: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1622 - accuracy: 0.9306 - val_loss: 1.9125 - val_accuracy: 0.6250\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9340\n",
      "Epoch 00047: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1359 - accuracy: 0.9340 - val_loss: 3.1606 - val_accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9410\n",
      "Epoch 00048: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1511 - accuracy: 0.9410 - val_loss: 1.7140 - val_accuracy: 0.6875\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9201\n",
      "Epoch 00049: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.2007 - accuracy: 0.9201 - val_loss: 0.8444 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9062\n",
      "Epoch 00050: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2094 - accuracy: 0.9062 - val_loss: 1.6211 - val_accuracy: 0.7188\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9479\n",
      "Epoch 00051: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1458 - accuracy: 0.9479 - val_loss: 1.1923 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.9410\n",
      "Epoch 00052: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1669 - accuracy: 0.9410 - val_loss: 1.2699 - val_accuracy: 0.7188\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9583\n",
      "Epoch 00053: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1387 - accuracy: 0.9583 - val_loss: 1.1396 - val_accuracy: 0.7188\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9444\n",
      "Epoch 00054: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1715 - accuracy: 0.9444 - val_loss: 1.3034 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9410\n",
      "Epoch 00055: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1540 - accuracy: 0.9410 - val_loss: 1.5099 - val_accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9375\n",
      "Epoch 00056: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1545 - accuracy: 0.9375 - val_loss: 0.8055 - val_accuracy: 0.7188\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9410\n",
      "Epoch 00057: val_loss did not improve from 0.76584\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1726 - accuracy: 0.9410 - val_loss: 1.0228 - val_accuracy: 0.7188\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.9618\n",
      "Epoch 00058: val_loss improved from 0.76584 to 0.59762, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1261 - accuracy: 0.9618 - val_loss: 0.5976 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9514\n",
      "Epoch 00059: val_loss improved from 0.59762 to 0.54041, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1367 - accuracy: 0.9514 - val_loss: 0.5404 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9479\n",
      "Epoch 00060: val_loss did not improve from 0.54041\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1615 - accuracy: 0.9479 - val_loss: 0.8944 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.9271\n",
      "Epoch 00061: val_loss did not improve from 0.54041\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2314 - accuracy: 0.9271 - val_loss: 0.6418 - val_accuracy: 0.7812\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9514\n",
      "Epoch 00062: val_loss improved from 0.54041 to 0.50889, saving model to own.h5\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1302 - accuracy: 0.9514 - val_loss: 0.5089 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9479\n",
      "Epoch 00063: val_loss did not improve from 0.50889\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1412 - accuracy: 0.9479 - val_loss: 1.0132 - val_accuracy: 0.7188\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9549\n",
      "Epoch 00064: val_loss did not improve from 0.50889\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1445 - accuracy: 0.9549 - val_loss: 1.1824 - val_accuracy: 0.7188\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9444\n",
      "Epoch 00065: val_loss did not improve from 0.50889\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1447 - accuracy: 0.9444 - val_loss: 0.8268 - val_accuracy: 0.8125\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9410\n",
      "Epoch 00066: val_loss improved from 0.50889 to 0.38261, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1681 - accuracy: 0.9410 - val_loss: 0.3826 - val_accuracy: 0.8125\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9549\n",
      "Epoch 00067: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1340 - accuracy: 0.9549 - val_loss: 0.6727 - val_accuracy: 0.8125\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9410\n",
      "Epoch 00068: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1685 - accuracy: 0.9410 - val_loss: 1.1425 - val_accuracy: 0.7188\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9271\n",
      "Epoch 00069: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1931 - accuracy: 0.9271 - val_loss: 0.7571 - val_accuracy: 0.7812\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9340\n",
      "Epoch 00070: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1846 - accuracy: 0.9340 - val_loss: 0.9503 - val_accuracy: 0.7812\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9479\n",
      "Epoch 00071: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1280 - accuracy: 0.9479 - val_loss: 0.4255 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9514\n",
      "Epoch 00072: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1385 - accuracy: 0.9514 - val_loss: 0.8550 - val_accuracy: 0.7812\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9340\n",
      "Epoch 00073: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1691 - accuracy: 0.9340 - val_loss: 0.7742 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9618\n",
      "Epoch 00074: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1388 - accuracy: 0.9618 - val_loss: 1.2714 - val_accuracy: 0.6562\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9357\n",
      "Epoch 00075: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1688 - accuracy: 0.9357 - val_loss: 0.5595 - val_accuracy: 0.8125\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9410\n",
      "Epoch 00076: val_loss did not improve from 0.38261\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1425 - accuracy: 0.9410 - val_loss: 0.4911 - val_accuracy: 0.7812\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9514\n",
      "Epoch 00077: val_loss improved from 0.38261 to 0.33900, saving model to own.h5\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.1621 - accuracy: 0.9514 - val_loss: 0.3390 - val_accuracy: 0.8438\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9479\n",
      "Epoch 00078: val_loss did not improve from 0.33900\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1391 - accuracy: 0.9479 - val_loss: 0.3571 - val_accuracy: 0.8125\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9444\n",
      "Epoch 00079: val_loss did not improve from 0.33900\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1971 - accuracy: 0.9444 - val_loss: 0.6680 - val_accuracy: 0.7812\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9410\n",
      "Epoch 00080: val_loss did not improve from 0.33900\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1650 - accuracy: 0.9410 - val_loss: 0.3698 - val_accuracy: 0.8438\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9653\n",
      "Epoch 00081: val_loss did not improve from 0.33900\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1296 - accuracy: 0.9653 - val_loss: 0.5359 - val_accuracy: 0.8125\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9375\n",
      "Epoch 00082: val_loss improved from 0.33900 to 0.13491, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1421 - accuracy: 0.9375 - val_loss: 0.1349 - val_accuracy: 0.9375\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9514\n",
      "Epoch 00083: val_loss did not improve from 0.13491\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1300 - accuracy: 0.9514 - val_loss: 0.1375 - val_accuracy: 0.9375\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9271\n",
      "Epoch 00084: val_loss did not improve from 0.13491\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1444 - accuracy: 0.9271 - val_loss: 0.3957 - val_accuracy: 0.8438\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9071\n",
      "Epoch 00085: val_loss did not improve from 0.13491\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2274 - accuracy: 0.9071 - val_loss: 0.1903 - val_accuracy: 0.9688\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9583\n",
      "Epoch 00086: val_loss improved from 0.13491 to 0.02434, saving model to own.h5\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1289 - accuracy: 0.9583 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9514\n",
      "Epoch 00087: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1498 - accuracy: 0.9514 - val_loss: 0.2258 - val_accuracy: 0.9062\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9583\n",
      "Epoch 00088: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1102 - accuracy: 0.9583 - val_loss: 0.2038 - val_accuracy: 0.9688\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9583\n",
      "Epoch 00089: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1224 - accuracy: 0.9583 - val_loss: 0.2987 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.9375\n",
      "Epoch 00090: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1758 - accuracy: 0.9375 - val_loss: 0.3681 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9722\n",
      "Epoch 00091: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1241 - accuracy: 0.9722 - val_loss: 0.0682 - val_accuracy: 0.9688\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9514\n",
      "Epoch 00092: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1681 - accuracy: 0.9514 - val_loss: 0.1295 - val_accuracy: 0.9688\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9410\n",
      "Epoch 00093: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1621 - accuracy: 0.9410 - val_loss: 0.1386 - val_accuracy: 0.9375\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9340\n",
      "Epoch 00094: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2254 - accuracy: 0.9340 - val_loss: 0.5058 - val_accuracy: 0.8438\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9722\n",
      "Epoch 00095: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1052 - accuracy: 0.9722 - val_loss: 0.2008 - val_accuracy: 0.8750\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9653\n",
      "Epoch 00096: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1351 - accuracy: 0.9653 - val_loss: 0.2336 - val_accuracy: 0.9062\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.9271\n",
      "Epoch 00097: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.2223 - accuracy: 0.9271 - val_loss: 0.1125 - val_accuracy: 0.9688\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9549\n",
      "Epoch 00098: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1481 - accuracy: 0.9549 - val_loss: 0.0917 - val_accuracy: 0.9375\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9653\n",
      "Epoch 00099: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0977 - accuracy: 0.9653 - val_loss: 0.1325 - val_accuracy: 0.9688\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9688\n",
      "Epoch 00100: val_loss did not improve from 0.02434\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0965 - accuracy: 0.9688 - val_loss: 0.1620 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[annealer,mc,es],\n",
    "    steps_per_epoch=stepsperepoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = validationsteps\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 38s 923ms/step - loss: 0.1388 - accuracy: 0.9480\n",
      "Validation Loss = 0.13875791430473328\n",
      "Validation Accuracy = 0.9479813575744629\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(validation_generator)\n",
    "print (\"Validation Loss = \" + str(preds[0]))\n",
    "print (\"Validation Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy : 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Train_acc\",\"Validation_acc\"])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Train_loss\",\"Validation Loss\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
